{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Устойчивост эл_сети.xlsx\",engine='openpyxl',sheet_name='Data_for_UCI_named')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  0.023892  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120 -0.025803    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984 -0.031810    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  0.037789  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  0.045263  unstable  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'unstable': 0, 'stable': 1}\n",
    "df.stabf = df.stabf.map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab  stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347      0  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957      1  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471      0  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871      0  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stab', 'stabf'], axis=1).values\n",
    "y = df.stabf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    X[:,i]=(X[:,i]-X[:,i].min())/(X[:,i].max()-X[:,i].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = Seniority_committee(N=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making hyperplane number 1\n",
      "X_train.shape[0] = 7000\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 60.499661684036255\n",
      "The minimum of the loss function: -264.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 26.034878253936768\n",
      "The minimum of the loss function: -12.178820020957273\n",
      "X_1.shape[0] = 264\n",
      "X_0.shape[0] = 13\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 63.74943971633911\n",
      "The minimum of the loss function: -403.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 24.504884243011475\n",
      "The minimum of the loss function: -56.72920981048451\n",
      "X_1.shape[0] = 403\n",
      "X_0.shape[0] = 112\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 64.373539686203\n",
      "The minimum of the loss function: -475.1796716048606\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 20.205622911453247\n",
      "The minimum of the loss function: -20.296787644715565\n",
      "X_1.shape[0] = 482\n",
      "X_0.shape[0] = 21\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 66.37308263778687\n",
      "The minimum of the loss function: -481.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 26.324190616607666\n",
      "The minimum of the loss function: -13.0\n",
      "X_1.shape[0] = 481\n",
      "X_0.shape[0] = 13\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 72.39039993286133\n",
      "The minimum of the loss function: -519.9239799403033\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 36.81321454048157\n",
      "The minimum of the loss function: -722.444183083515\n",
      "X_1.shape[0] = 619\n",
      "X_0.shape[0] = 919\n",
      "Making hyperplane number 2\n",
      "X_train.shape[0] = 6081\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 1877.4983716011047\n",
      "The minimum of the loss function: -278.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 28.12901210784912\n",
      "The minimum of the loss function: -18.120729564174113\n",
      "X_1.shape[0] = 278\n",
      "X_0.shape[0] = 33\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 55.20187830924988\n",
      "The minimum of the loss function: -453.4403142327584\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 21.95294952392578\n",
      "The minimum of the loss function: -16.0\n",
      "X_1.shape[0] = 478\n",
      "X_0.shape[0] = 16\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 53.418638467788696\n",
      "The minimum of the loss function: -355.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 23.01847743988037\n",
      "The minimum of the loss function: -18.0\n",
      "X_1.shape[0] = 355\n",
      "X_0.shape[0] = 18\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 57.37048554420471\n",
      "The minimum of the loss function: -439.97716147589233\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 21.072362422943115\n",
      "The minimum of the loss function: -11.0\n",
      "X_1.shape[0] = 475\n",
      "X_0.shape[0] = 11\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 60.571091175079346\n",
      "The minimum of the loss function: -579.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 23.87345027923584\n",
      "The minimum of the loss function: -48.58312270843213\n",
      "X_1.shape[0] = 579\n",
      "X_0.shape[0] = 67\n",
      "Making hyperplane number 3\n",
      "X_train.shape[0] = 5502\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 45.844910860061646\n",
      "The minimum of the loss function: -225.81599009392983\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 23.36967158317566\n",
      "The minimum of the loss function: -29.075827784534106\n",
      "X_1.shape[0] = 233\n",
      "X_0.shape[0] = 36\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 52.18807888031006\n",
      "The minimum of the loss function: -197.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 26.107467651367188\n",
      "The minimum of the loss function: -25.0\n",
      "X_1.shape[0] = 197\n",
      "X_0.shape[0] = 25\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 45.39977526664734\n",
      "The minimum of the loss function: -192.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 26.262385606765747\n",
      "The minimum of the loss function: -29.0\n",
      "X_1.shape[0] = 192\n",
      "X_0.shape[0] = 29\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 53.31708908081055\n",
      "The minimum of the loss function: -237.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 25.412307739257812\n",
      "The minimum of the loss function: -21.0\n",
      "X_1.shape[0] = 237\n",
      "X_0.shape[0] = 21\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 56.86234521865845\n",
      "The minimum of the loss function: -355.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 33.00135564804077\n",
      "The minimum of the loss function: -38.0\n",
      "X_1.shape[0] = 355\n",
      "X_0.shape[0] = 38\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 50.24498796463013\n",
      "The minimum of the loss function: -331.1766097163005\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 30.688204288482666\n",
      "The minimum of the loss function: -48.0\n",
      "X_1.shape[0] = 393\n",
      "X_0.shape[0] = 48\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 51.27359056472778\n",
      "The minimum of the loss function: -437.6655536765569\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 27.10358428955078\n",
      "The minimum of the loss function: -550.215085480352\n",
      "X_1.shape[0] = 452\n",
      "X_0.shape[0] = 703\n",
      "Making hyperplane number 4\n",
      "X_train.shape[0] = 4799\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 55.296032190322876\n",
      "The minimum of the loss function: -173.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 30.62130355834961\n",
      "The minimum of the loss function: -24.0\n",
      "X_1.shape[0] = 173\n",
      "X_0.shape[0] = 24\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 64.66739821434021\n",
      "The minimum of the loss function: -165.98505717636723\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 29.35601234436035\n",
      "The minimum of the loss function: -35.0\n",
      "X_1.shape[0] = 169\n",
      "X_0.shape[0] = 35\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 60.709794759750366\n",
      "The minimum of the loss function: -210.96224718568504\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 25.126484870910645\n",
      "The minimum of the loss function: -29.0\n",
      "X_1.shape[0] = 214\n",
      "X_0.shape[0] = 29\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 49.66712832450867\n",
      "The minimum of the loss function: -238.86068534185864\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 23.445642709732056\n",
      "The minimum of the loss function: -20.0\n",
      "X_1.shape[0] = 413\n",
      "X_0.shape[0] = 20\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 51.760711431503296\n",
      "The minimum of the loss function: -358.57001661732136\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 24.75390338897705\n",
      "The minimum of the loss function: -31.0\n",
      "X_1.shape[0] = 359\n",
      "X_0.shape[0] = 31\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First approximation is obtained\n",
      "Time taken for optimization: 50.49716281890869\n",
      "The minimum of the loss function: -336.5217592870665\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 25.879375219345093\n",
      "The minimum of the loss function: -37.530902782616536\n",
      "X_1.shape[0] = 350\n",
      "X_0.shape[0] = 48\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 48.65535354614258\n",
      "The minimum of the loss function: -400.1810102525392\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 26.08391571044922\n",
      "The minimum of the loss function: -74.80591262891392\n",
      "X_1.shape[0] = 471\n",
      "X_0.shape[0] = 112\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 50.17775797843933\n",
      "The minimum of the loss function: -457.05067419372494\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 22.259212493896484\n",
      "The minimum of the loss function: -115.37409006516484\n",
      "X_1.shape[0] = 507\n",
      "X_0.shape[0] = 180\n",
      "Making hyperplane number 5\n",
      "X_train.shape[0] = 4292\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 36.430291175842285\n",
      "The minimum of the loss function: -92.33858657348503\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 25.990145444869995\n",
      "The minimum of the loss function: -78.0\n",
      "X_1.shape[0] = 100\n",
      "X_0.shape[0] = 78\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 38.09127902984619\n",
      "The minimum of the loss function: -132.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 24.892598390579224\n",
      "The minimum of the loss function: -45.0\n",
      "X_1.shape[0] = 132\n",
      "X_0.shape[0] = 45\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 34.04685592651367\n",
      "The minimum of the loss function: -133.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 23.5598304271698\n",
      "The minimum of the loss function: -39.53847617190844\n",
      "X_1.shape[0] = 133\n",
      "X_0.shape[0] = 41\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 34.644410848617554\n",
      "The minimum of the loss function: -144.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 25.92239284515381\n",
      "The minimum of the loss function: -43.350001288556236\n",
      "X_1.shape[0] = 144\n",
      "X_0.shape[0] = 44\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 32.76417255401611\n",
      "The minimum of the loss function: -121.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 32.54317116737366\n",
      "The minimum of the loss function: -40.0\n",
      "X_1.shape[0] = 121\n",
      "X_0.shape[0] = 40\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 44.48698163032532\n",
      "The minimum of the loss function: -159.6712282057338\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 36.30345821380615\n",
      "The minimum of the loss function: -50.506329766738766\n",
      "X_1.shape[0] = 184\n",
      "X_0.shape[0] = 53\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 47.497374057769775\n",
      "The minimum of the loss function: -199.56954135214454\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 32.73056387901306\n",
      "The minimum of the loss function: -157.23408261782896\n",
      "X_1.shape[0] = 231\n",
      "X_0.shape[0] = 160\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 49.10882544517517\n",
      "The minimum of the loss function: -234.75349565288218\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 30.55172824859619\n",
      "The minimum of the loss function: -153.0\n",
      "X_1.shape[0] = 259\n",
      "X_0.shape[0] = 225\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 45.01664590835571\n",
      "The minimum of the loss function: -281.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 43.49696207046509\n",
      "The minimum of the loss function: -575.4557569161107\n",
      "X_1.shape[0] = 366\n",
      "X_0.shape[0] = 1408\n",
      "Making hyperplane number 6\n",
      "X_train.shape[0] = 2884\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 38.36588954925537\n",
      "The minimum of the loss function: -155.19533298638976\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 26.211846113204956\n",
      "The minimum of the loss function: -18.0\n",
      "X_1.shape[0] = 161\n",
      "X_0.shape[0] = 18\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 34.36834454536438\n",
      "The minimum of the loss function: -138.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 20.82074236869812\n",
      "The minimum of the loss function: -20.0\n",
      "X_1.shape[0] = 138\n",
      "X_0.shape[0] = 20\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 29.77753186225891\n",
      "The minimum of the loss function: -133.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 24.60170555114746\n",
      "The minimum of the loss function: -27.0\n",
      "X_1.shape[0] = 133\n",
      "X_0.shape[0] = 27\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 38.06713032722473\n",
      "The minimum of the loss function: -157.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 23.389747619628906\n",
      "The minimum of the loss function: -39.0\n",
      "X_1.shape[0] = 157\n",
      "X_0.shape[0] = 39\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 32.91105556488037\n",
      "The minimum of the loss function: -180.17831212773066\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 24.897344827651978\n",
      "The minimum of the loss function: -34.0\n",
      "X_1.shape[0] = 185\n",
      "X_0.shape[0] = 34\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 35.688348054885864\n",
      "The minimum of the loss function: -177.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 25.363157749176025\n",
      "The minimum of the loss function: -35.213904730758706\n",
      "X_1.shape[0] = 177\n",
      "X_0.shape[0] = 39\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 41.097408056259155\n",
      "The minimum of the loss function: -221.81058545757634\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 22.952748775482178\n",
      "The minimum of the loss function: -36.0\n",
      "X_1.shape[0] = 241\n",
      "X_0.shape[0] = 36\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 32.51100969314575\n",
      "The minimum of the loss function: -236.5388307540086\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 21.64781951904297\n",
      "The minimum of the loss function: -61.0\n",
      "X_1.shape[0] = 249\n",
      "X_0.shape[0] = 61\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 33.719879150390625\n",
      "The minimum of the loss function: -244.14120419020503\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 21.943575620651245\n",
      "The minimum of the loss function: -104.26012054001595\n",
      "X_1.shape[0] = 296\n",
      "X_0.shape[0] = 166\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 41.304861068725586\n",
      "The minimum of the loss function: -271.7102757476804\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 39.376293420791626\n",
      "The minimum of the loss function: -145.0\n",
      "X_1.shape[0] = 410\n",
      "X_0.shape[0] = 499\n",
      "Cutted data shape is not enough\n",
      "Optimization is started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First approximation is obtained\n",
      "Time taken for optimization: 69.49002242088318\n",
      "The minimum of the loss function: -332.0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "Time taken for optimization: 84.75672364234924\n",
      "The minimum of the loss function: -698.2272638423916\n",
      "X_1.shape[0] = 676\n",
      "X_0.shape[0] = 2100\n"
     ]
    }
   ],
   "source": [
    "sc.fit(X_train, y_train, maxiter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_weights = sc.weights_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0,\n",
       "  array([  617.43525033,   539.73595299,   485.01990141,   476.99384603,\n",
       "         -2257.95095421,  -723.06823243,  -799.98288163,  -888.85836126,\n",
       "           635.64094694,   596.44673478,    98.00411494,   303.59060635]),\n",
       "  0.003264417845484222),\n",
       " 2: (1,\n",
       "  array([ -248.21422733,  -399.13967414, -1803.65310765,  -227.20625925,\n",
       "          1500.33791088,   556.79677475,   600.54208049,   488.98173997,\n",
       "          -806.69535206,  -802.93057197,    28.2307978 ,  -853.45366366]),\n",
       "  1.0),\n",
       " 3: (0,\n",
       "  array([  8.81737104,  13.14315127,  23.34389129,  21.41338772,\n",
       "         -62.52249616, -24.47233907, -24.70956411, -20.66899839,\n",
       "          -1.20584566,   7.41496479,  17.72079434,  17.84662403]),\n",
       "  0.015647226173541962),\n",
       " 4: (1,\n",
       "  array([-19.99798397, -44.05879675,  -0.20737807, -16.00983758,\n",
       "          62.45366298,  21.49289305,  23.76742717,  24.96155423,\n",
       "         -31.55335624, -12.61178314, -38.13047017, -29.47349193]),\n",
       "  0.9822485207100592),\n",
       " 5: (0,\n",
       "  array([ 17.0575306 ,  13.2653159 ,  13.05772842,  19.75028383,\n",
       "         -53.91120524, -20.97021009, -17.6915074 , -16.67613837,\n",
       "          10.85936032,   6.27909581,  15.42687671,   9.6670957 ]),\n",
       "  0.12144886363636363),\n",
       " 6: (0,\n",
       "  array([ 14.10568525,   6.28034401,  16.31025016,  55.34938451,\n",
       "         -58.9768036 , -22.42018016, -20.36955492, -28.05337613,\n",
       "          19.48473545,  31.60752919,  21.52439686,   4.18070775]),\n",
       "  0.3357142857142857)}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_1 = Seniority_committee(N=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_1.weights_hp = optim_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = sc_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = sc_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6953112577839854"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6854070352149612"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seniority_committee:\n",
    "    \"\"\"\n",
    "        ML Algo based on the seniority committee method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        \"\"\"\n",
    "            :param N: число наблюдений, находящихся выше гиперплоскости\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.L = -1\n",
    "        self.N = N\n",
    "        self.weights_hp = dict() # здесь будут записаны оптимальные веса гиперплоскостей в виде: \n",
    "                                 # {'num_hyperplane': (voted_class, optim_weights, probability)}\n",
    "        self.optim_params = dict() # здесь будут записаны параметры оптимизации гиперплоскостей в виде:\n",
    "                   # {'cycle_range': int, 'disp': bool, 'adaptive': bool, 'maxiter': int or None, 'xatol': float or None}\n",
    "                   # значение параметров дано в описании метода make_hyperplane\n",
    "        \n",
    "        \n",
    "    def probability(self, X, w):\n",
    "        \"\"\"\n",
    "            Принимает на вход матрицу фичей и вектор весов\n",
    "            Возвращает предсказание вероятность того, что y = 1 при фиксированных x, P(y=1|x)\n",
    "\n",
    "            :param X: матрица признаков \n",
    "            :param w: вектор весов\n",
    "            :returns: вероятность того, что y = 1 при фиксированных x, P(y=1|x) ## вектор вероятностей = ReLU1(X.T*w)\n",
    "        \"\"\"\n",
    "        \n",
    "        linear = np.dot(X, w)\n",
    "        linear[linear < 0] = 0\n",
    "        linear[linear > 1] = 1\n",
    "        \n",
    "        return linear\n",
    "    \n",
    "    \n",
    "    def compute_loss(self, X, y, w):\n",
    "        \"\"\"\n",
    "            Принимает на вход матрицу весов, вектор ответов, вектор весов и параметр L, \n",
    "            влияющий на долю класса 0 в отсекающей гиперплоскости.\n",
    "            Выдаёт на выход значение функции потерь\n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :param w: вектор целевой переменной\n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь\n",
    "        \"\"\"\n",
    "        \n",
    "        p1 = self.probability(X, w)\n",
    "        loss = np.sum((self.L - (self.L + 1) * y) * p1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def compute_train_loss_class_0(self, w):\n",
    "        \"\"\"\n",
    "            Function that we want to minimize, the committee member votes for class 1\n",
    "            \n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь на обучающей выборке, когда член коммитета голосует за класс 0\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        return self.compute_loss(self.X_train, 1 - self.y_train, w)\n",
    "    \n",
    "    \n",
    "    def compute_train_loss_class_1(self, w):\n",
    "        \"\"\"\n",
    "            Function that we want to minimize, the committee member votes for class 1\n",
    "            \n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь на обучающей выборке, когда член коммитета голосует за класс 1\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        return self.compute_loss(self.X_train, self.y_train, w)\n",
    "    \n",
    "    \n",
    "    def make_hyperplane(self, class_num, X_train, c=0.1, cycle_range=100, disp=False, \\\n",
    "                        adaptive=True, maxiter=None, xatol=None):\n",
    "        \"\"\"\n",
    "            Function that makes one of three hyperplanes\n",
    "            \n",
    "            :param class_num: класс, за который голосует данный член комитета: [0, 1]\n",
    "            :param X_train: матрица признаков обучающей выборки\n",
    "            :param с: вспомогательный коэффициент для выбора начального приближения\n",
    "            :param cycle_range: количество итераций минимизации функции потерь\n",
    "            Параметры оптимизации с помощью алгоритма Нелдера-Мида:\n",
    "                :param disp: bool: печать сообщения о сходимости\n",
    "                :param adaptive: bool: адаптация параметров алгоритма для размерности задачи (полезно при больших размерностях)\n",
    "                :param maxiter: максимально допустимое количество итераций при оптимизации\n",
    "                :param xatol: абсолютная ошибка на оптимальных точках между итерациями, приемлемая для сходимости\n",
    "            :returns: значение функции потерь на тестовой выборке\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Using make_hyperplane method before fitting')\n",
    "        if class_num not in [0, 1]:\n",
    "            raise Exception('Only binary classification is available, class_num should be 0 or 1')\n",
    "        \n",
    "        optim_result = []\n",
    "        optim_result_more_precise = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print('Optimization is started')\n",
    "\n",
    "        for i in range(cycle_range):\n",
    "            \n",
    "            start_w = np.array((np.random.rand(X_train.shape[1]) - 0.5) * c)\n",
    "            \n",
    "            if class_num == 1:\n",
    "                res = minimize(self.compute_train_loss_class_1, x0=start_w, method='Nelder-Mead', \\\n",
    "                               options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "            elif class_num == 0:\n",
    "                res = minimize(self.compute_train_loss_class_0, x0=start_w, method='Nelder-Mead', \\\n",
    "                               options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "#             if res.fun < 0:\n",
    "            optim_result.append(res.x)\n",
    "            \n",
    "        \n",
    "        if optim_result == []:\n",
    "            raise Exception('We\\'ve not get any satisfying first approximation')\n",
    "\n",
    "        print('First approximation is obtained')\n",
    "        \n",
    "        for start_w_new in optim_result:\n",
    "            \n",
    "            if class_num == 1:\n",
    "                res = minimize(self.compute_train_loss_class_1, x0=start_w_new, method='Nelder-Mead', \\\n",
    "                         options={'disp': False, 'adaptive':True, 'xatol':1})\n",
    "            elif class_num == 0:\n",
    "                res = minimize(self.compute_train_loss_class_0, x0=start_w_new, method='Nelder-Mead', \\\n",
    "                         options={'disp': False, 'adaptive':True, 'xatol':1})\n",
    "\n",
    "            for k in range(2):\n",
    "                if class_num == 1:\n",
    "                    res = minimize(self.compute_train_loss_class_1, x0=res.x, method='Nelder-Mead', \\\n",
    "                             options={'disp': False, 'adaptive':True})\n",
    "                elif class_num == 0:\n",
    "                    res = minimize(self.compute_train_loss_class_0, x0=res.x, method='Nelder-Mead', \\\n",
    "                             options={'disp': False, 'adaptive':True})\n",
    "\n",
    "            optim_result_more_precise += [[res.fun, res.x]]\n",
    "\n",
    "        optim_result_more_precise = pd.DataFrame(optim_result_more_precise)\n",
    "        optim_result_more_precise = optim_result_more_precise.sort_values(0).head(1)\n",
    "        hyperplane_coefficients = optim_result_more_precise[1].values[0]\n",
    "        print('Time taken for optimization: {0}'.format(time.time() - start_time))\n",
    "        print('The minimum of the loss function: {0}'.format(optim_result_more_precise[0].values[0]))\n",
    "\n",
    "        return hyperplane_coefficients\n",
    "        \n",
    "    \n",
    "    def cutter(self, X, w):\n",
    "        \"\"\"\n",
    "            Function that makes binary targets for rational numbers\n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :param w: вектор оптимальных весов\n",
    "            :returns: бинаризованные предсказания целевой переменной\n",
    "        \"\"\"\n",
    "        \n",
    "        linear = np.dot(X, w)\n",
    "        linear[linear < 0] = 0\n",
    "        \n",
    "        return np.sign(linear)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, cycle_range=100, disp=False, adaptive=True, maxiter=10, xatol=0.3):\n",
    "        \"\"\"\n",
    "            Fits the algorithm on the train sample \n",
    "            \n",
    "            :param X: матрица признаков, обучающая выборка\n",
    "            :param y: вектор истинных значений целевой переменной обучающей выборки\n",
    "            Параметры оптимизации с помощью алгоритма Нелдера-Мида:\n",
    "                :param disp: bool: печать сообщения о сходимости\n",
    "                :param adaptive: bool: адаптация параметров алгоритма для размерности задачи (полезно при больших размерностях)\n",
    "                :param maxiter: максимально допустимое количество итераций при оптимизации\n",
    "                :param xatol: абсолютная ошибка на оптимальных точках между итерациями, приемлемая для сходимости\n",
    "            :returns: -, но на выходе обученная моделька\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.optim_params = {'cycle_range': cycle_range, 'disp': disp, 'adaptive': adaptive, \\\n",
    "                             'maxiter': maxiter, 'xatol': xatol}\n",
    "        \n",
    "        hp_num = 1\n",
    "        \n",
    "        while self.X_train.shape[0] > 2 * self.N:\n",
    "            \n",
    "            print('Making hyperplane number {}'.format(hp_num))\n",
    "            print('X_train.shape[0] = {}'.format(self.X_train.shape[0]))\n",
    "            \n",
    "            k = 10\n",
    "            \n",
    "            while True:\n",
    "                \n",
    "                print('k = {}'.format(k))\n",
    "                \n",
    "                self.L = 2 ** k\n",
    "                \n",
    "                print('L = {}'.format(L))\n",
    "                \n",
    "                print('Optimizing hyperplane for class 1')\n",
    "                \n",
    "                hp_weights_class_1 = self.make_hyperplane(class_num=1, X_train=self.X_train, \\\n",
    "                                                     c=0.1, cycle_range=self.optim_params['cycle_range'], \\\n",
    "                                                     disp=self.optim_params['disp'], \\\n",
    "                                                     adaptive=self.optim_params['adaptive'], \\\n",
    "                                                     maxiter=self.optim_params['maxiter'], \\\n",
    "                                                     xatol=self.optim_params['xatol'])\n",
    "                \n",
    "                print('Optimizing hyperplane for class 0')\n",
    "                \n",
    "                hp_weights_class_0 = self.make_hyperplane(class_num=0, X_train=self.X_train, \\\n",
    "                                                     c=0.1, cycle_range=self.optim_params['cycle_range'], \\\n",
    "                                                     disp=self.optim_params['disp'], \\\n",
    "                                                     adaptive=self.optim_params['adaptive'], \\\n",
    "                                                     maxiter=self.optim_params['maxiter'], \\\n",
    "                                                     xatol=self.optim_params['xatol'])\n",
    "                \n",
    "                cut_1 = self.cutter(self.X_train, hp_weights_class_1)\n",
    "                cut_0 = self.cutter(self.X_train, hp_weights_class_0)\n",
    "                X_1 = self.X_train[cut_1 == 1]\n",
    "                y_1 = self.y_train[cut_1 == 1]\n",
    "                X_0 = self.X_train[cut_0 == 1]\n",
    "                y_0 = self.y_train[cut_0 == 1]\n",
    "                \n",
    "                print('X_1.shape[0] = {}'.format(X_1.shape[0]))\n",
    "                print('X_0.shape[0] = {}'.format(X_0.shape[0]))\n",
    "                \n",
    "                if X_1.shape[0] < self.N and X_0.shape[0] < self.N:\n",
    "                    \n",
    "                    print('Cutted data shape is not enough\\n')\n",
    "                    k -= 1\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    if X_1.shape[0] >= X_0.shape[0]:\n",
    "                        \n",
    "                        proba = y_1.sum() / len(y_1)\n",
    "                        self.weights_hp[hp_num] = (1, hp_weights_class_1, proba)\n",
    "                        \n",
    "                        self.X_train = self.X_train[cut_1 == 0]\n",
    "                        self.y_train = self.y_train[cut_1 == 0]\n",
    "                        \n",
    "                    elif X_1.shape[0] < X_0.shape[0]:\n",
    "                        \n",
    "                        proba = y_0.sum() / len(y_0)\n",
    "                        self.weights_hp[hp_num] = (0, hp_weights_class_0, proba)\n",
    "                        \n",
    "                        self.X_train = self.X_train[cut_0 == 0]\n",
    "                        self.y_train = self.y_train[cut_0 == 0]\n",
    "                        \n",
    "                    hp_num += 1\n",
    "                    print()\n",
    "                    break\n",
    "                \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Makes predict_proba for the sample\n",
    "            \n",
    "            :param X: матрица признаков, обучающая выборка\n",
    "            :returns: предсказания вероятностей отнесения к классу 1\n",
    "        \"\"\"\n",
    "        test_ = X.copy()\n",
    "        \n",
    "        if self.weights_hp == {}:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        predictions = pd.DataFrame({'proba': np.zeros(X.shape[0]), 'is_scored': False})\n",
    "        \n",
    "        for hp_num in self.weights_hp.keys():\n",
    "            \n",
    "            class_num, weights, proba = self.weights_hp[hp_num]\n",
    "            \n",
    "            cut = self.cutter(test_, weights)\n",
    "            \n",
    "            X_ = test_[cut == 1]\n",
    "            test_ = test_[cut == 0]\n",
    "            \n",
    "            k = 0\n",
    "            for i in range(predictions.shape[0]):\n",
    "                \n",
    "                if predictions.loc[i, 'is_scored'] == False:\n",
    "                    if cut[k] == True:\n",
    "                        predictions.loc[i, 'proba'] = proba\n",
    "                        predictions.loc[i, 'is_scored'] = True\n",
    "                    k += 1\n",
    "                    \n",
    "        return predictions['proba'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
