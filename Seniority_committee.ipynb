{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGS: \n",
    "## N = 500\n",
    "### Nelder-Mead : время работы 290 секунд, Gini: train 0.8, test 0.77\n",
    "### differential-evolution : время работы порядка 15 минут, Gini: train 0.76, test 0.75 -- default params\n",
    "### BFGS : время работы 95 секунд, Gini: train 0.8, test 0.76 -- default params\n",
    "### CG : время работы 127 секунд, Gini: train 0.77, test 0.75 -- default params\n",
    "### SLSQP : время работы 42 секунд, Gini: train 0.81, test 0.776 -- default params\n",
    "### COBYLA : время работы 84 секунд, Gini: train 0.75, test 0.75 -- default params\n",
    "### TNC : время работы 590 секунд, Gini: train 0.82, test 0.80 -- default params\n",
    "\n",
    "## N = 200\n",
    "### TNC : время работы 834 секунд, Gini: train 0.84, test 0.83 -- default params\n",
    "\n",
    "## Сравнение с другими моделями:\n",
    "### RandomForestClassifier: Gini: train 1.0, test 0.80 -- default params\n",
    "### LGBMClassifier: Gini: train 0.998, test 0.86 -- default params\n",
    "### CatBoostClassifier: Gini: train 0.997, test 0.89 -- default params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Устойчивост эл_сети.xlsx\",engine='openpyxl',sheet_name='Data_for_UCI_named')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  0.023892  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120 -0.025803    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984 -0.031810    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  0.037789  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  0.045263  unstable  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'unstable': 0, 'stable': 1}\n",
    "df.stabf = df.stabf.map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab  stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347      0  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957      1  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471      0  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871      0  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stab', 'stabf'], axis=1).values\n",
    "y = df.stabf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    X[:,i]=(X[:,i]-X[:,i].min())/(X[:,i].max()-X[:,i].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Gini = 0.7760174451729984\n",
      "Test Gini = 0.6537581922529714\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=7)\n",
    "tree.fit(X_train, y_train)\n",
    "train_preds = tree.predict(X_train)\n",
    "test_preds = tree.predict(X_test)\n",
    "print('Train Gini = {}'.format(2 * roc_auc_score(y_train, train_preds) - 1))\n",
    "print('Test Gini = {}'.format(2 * roc_auc_score(y_test, test_preds) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "train_preds = rf.predict(X_train)\n",
    "test_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Gini = 1.0\n",
      "Test Gini = 0.8029251258579901\n"
     ]
    }
   ],
   "source": [
    "print('Train Gini = {}'.format(2 * roc_auc_score(y_train, train_preds) - 1))\n",
    "print('Test Gini = {}'.format(2 * roc_auc_score(y_test, test_preds) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X_train, y_train)\n",
    "train_preds = lgbm.predict(X_train)\n",
    "test_preds = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Gini = 0.9985429211742267\n",
      "Test Gini = 0.8636193729678863\n"
     ]
    }
   ],
   "source": [
    "print('Train Gini = {}'.format(2 * roc_auc_score(y_train, train_preds) - 1))\n",
    "print('Test Gini = {}'.format(2 * roc_auc_score(y_test, test_preds) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.023648\n",
      "0:\tlearn: 0.6756988\ttotal: 6.02ms\tremaining: 6.01s\n",
      "1:\tlearn: 0.6579684\ttotal: 11.3ms\tremaining: 5.66s\n",
      "2:\tlearn: 0.6418132\ttotal: 16.6ms\tremaining: 5.52s\n",
      "3:\tlearn: 0.6259760\ttotal: 21.6ms\tremaining: 5.38s\n",
      "4:\tlearn: 0.6109066\ttotal: 26.6ms\tremaining: 5.3s\n",
      "5:\tlearn: 0.5975475\ttotal: 33.1ms\tremaining: 5.48s\n",
      "6:\tlearn: 0.5844479\ttotal: 46.1ms\tremaining: 6.54s\n",
      "7:\tlearn: 0.5722559\ttotal: 52.6ms\tremaining: 6.52s\n",
      "8:\tlearn: 0.5611067\ttotal: 63.4ms\tremaining: 6.98s\n",
      "9:\tlearn: 0.5509317\ttotal: 68.8ms\tremaining: 6.81s\n",
      "10:\tlearn: 0.5404309\ttotal: 73.8ms\tremaining: 6.64s\n",
      "11:\tlearn: 0.5310707\ttotal: 80.8ms\tremaining: 6.65s\n",
      "12:\tlearn: 0.5222641\ttotal: 85.8ms\tremaining: 6.51s\n",
      "13:\tlearn: 0.5137257\ttotal: 90.8ms\tremaining: 6.4s\n",
      "14:\tlearn: 0.5061233\ttotal: 96.4ms\tremaining: 6.33s\n",
      "15:\tlearn: 0.4978769\ttotal: 101ms\tremaining: 6.24s\n",
      "16:\tlearn: 0.4904899\ttotal: 107ms\tremaining: 6.21s\n",
      "17:\tlearn: 0.4833668\ttotal: 113ms\tremaining: 6.14s\n",
      "18:\tlearn: 0.4772463\ttotal: 118ms\tremaining: 6.08s\n",
      "19:\tlearn: 0.4714114\ttotal: 122ms\tremaining: 6s\n",
      "20:\tlearn: 0.4645535\ttotal: 127ms\tremaining: 5.94s\n",
      "21:\tlearn: 0.4588031\ttotal: 132ms\tremaining: 5.88s\n",
      "22:\tlearn: 0.4521681\ttotal: 137ms\tremaining: 5.82s\n",
      "23:\tlearn: 0.4469947\ttotal: 142ms\tremaining: 5.77s\n",
      "24:\tlearn: 0.4416335\ttotal: 147ms\tremaining: 5.72s\n",
      "25:\tlearn: 0.4366236\ttotal: 152ms\tremaining: 5.68s\n",
      "26:\tlearn: 0.4320905\ttotal: 157ms\tremaining: 5.64s\n",
      "27:\tlearn: 0.4271535\ttotal: 161ms\tremaining: 5.6s\n",
      "28:\tlearn: 0.4228437\ttotal: 167ms\tremaining: 5.6s\n",
      "29:\tlearn: 0.4188519\ttotal: 174ms\tremaining: 5.62s\n",
      "30:\tlearn: 0.4143661\ttotal: 181ms\tremaining: 5.66s\n",
      "31:\tlearn: 0.4103887\ttotal: 187ms\tremaining: 5.67s\n",
      "32:\tlearn: 0.4062783\ttotal: 194ms\tremaining: 5.67s\n",
      "33:\tlearn: 0.4024523\ttotal: 199ms\tremaining: 5.66s\n",
      "34:\tlearn: 0.3991426\ttotal: 205ms\tremaining: 5.64s\n",
      "35:\tlearn: 0.3953943\ttotal: 210ms\tremaining: 5.62s\n",
      "36:\tlearn: 0.3920940\ttotal: 216ms\tremaining: 5.61s\n",
      "37:\tlearn: 0.3885612\ttotal: 221ms\tremaining: 5.59s\n",
      "38:\tlearn: 0.3845846\ttotal: 227ms\tremaining: 5.59s\n",
      "39:\tlearn: 0.3813828\ttotal: 232ms\tremaining: 5.57s\n",
      "40:\tlearn: 0.3782724\ttotal: 238ms\tremaining: 5.56s\n",
      "41:\tlearn: 0.3752122\ttotal: 243ms\tremaining: 5.54s\n",
      "42:\tlearn: 0.3725415\ttotal: 248ms\tremaining: 5.53s\n",
      "43:\tlearn: 0.3695127\ttotal: 254ms\tremaining: 5.51s\n",
      "44:\tlearn: 0.3665555\ttotal: 259ms\tremaining: 5.5s\n",
      "45:\tlearn: 0.3636440\ttotal: 267ms\tremaining: 5.53s\n",
      "46:\tlearn: 0.3607879\ttotal: 275ms\tremaining: 5.57s\n",
      "47:\tlearn: 0.3580326\ttotal: 280ms\tremaining: 5.55s\n",
      "48:\tlearn: 0.3549642\ttotal: 285ms\tremaining: 5.54s\n",
      "49:\tlearn: 0.3521322\ttotal: 292ms\tremaining: 5.54s\n",
      "50:\tlearn: 0.3501405\ttotal: 297ms\tremaining: 5.53s\n",
      "51:\tlearn: 0.3476809\ttotal: 302ms\tremaining: 5.51s\n",
      "52:\tlearn: 0.3458517\ttotal: 308ms\tremaining: 5.5s\n",
      "53:\tlearn: 0.3435807\ttotal: 313ms\tremaining: 5.49s\n",
      "54:\tlearn: 0.3413263\ttotal: 323ms\tremaining: 5.55s\n",
      "55:\tlearn: 0.3388909\ttotal: 328ms\tremaining: 5.53s\n",
      "56:\tlearn: 0.3364764\ttotal: 334ms\tremaining: 5.52s\n",
      "57:\tlearn: 0.3342969\ttotal: 340ms\tremaining: 5.52s\n",
      "58:\tlearn: 0.3319267\ttotal: 346ms\tremaining: 5.52s\n",
      "59:\tlearn: 0.3300005\ttotal: 353ms\tremaining: 5.52s\n",
      "60:\tlearn: 0.3278523\ttotal: 361ms\tremaining: 5.56s\n",
      "61:\tlearn: 0.3256754\ttotal: 368ms\tremaining: 5.57s\n",
      "62:\tlearn: 0.3234310\ttotal: 375ms\tremaining: 5.57s\n",
      "63:\tlearn: 0.3217725\ttotal: 380ms\tremaining: 5.56s\n",
      "64:\tlearn: 0.3201445\ttotal: 389ms\tremaining: 5.59s\n",
      "65:\tlearn: 0.3184289\ttotal: 395ms\tremaining: 5.59s\n",
      "66:\tlearn: 0.3162689\ttotal: 401ms\tremaining: 5.59s\n",
      "67:\tlearn: 0.3147535\ttotal: 406ms\tremaining: 5.57s\n",
      "68:\tlearn: 0.3132197\ttotal: 411ms\tremaining: 5.55s\n",
      "69:\tlearn: 0.3116645\ttotal: 416ms\tremaining: 5.53s\n",
      "70:\tlearn: 0.3103256\ttotal: 422ms\tremaining: 5.52s\n",
      "71:\tlearn: 0.3085155\ttotal: 427ms\tremaining: 5.5s\n",
      "72:\tlearn: 0.3066889\ttotal: 432ms\tremaining: 5.48s\n",
      "73:\tlearn: 0.3052289\ttotal: 437ms\tremaining: 5.46s\n",
      "74:\tlearn: 0.3036481\ttotal: 442ms\tremaining: 5.45s\n",
      "75:\tlearn: 0.3024332\ttotal: 446ms\tremaining: 5.43s\n",
      "76:\tlearn: 0.3012565\ttotal: 451ms\tremaining: 5.41s\n",
      "77:\tlearn: 0.2996492\ttotal: 456ms\tremaining: 5.39s\n",
      "78:\tlearn: 0.2985372\ttotal: 461ms\tremaining: 5.38s\n",
      "79:\tlearn: 0.2970722\ttotal: 466ms\tremaining: 5.36s\n",
      "80:\tlearn: 0.2953869\ttotal: 471ms\tremaining: 5.34s\n",
      "81:\tlearn: 0.2938002\ttotal: 476ms\tremaining: 5.33s\n",
      "82:\tlearn: 0.2923224\ttotal: 481ms\tremaining: 5.31s\n",
      "83:\tlearn: 0.2912261\ttotal: 486ms\tremaining: 5.29s\n",
      "84:\tlearn: 0.2897854\ttotal: 490ms\tremaining: 5.28s\n",
      "85:\tlearn: 0.2886768\ttotal: 495ms\tremaining: 5.26s\n",
      "86:\tlearn: 0.2873438\ttotal: 500ms\tremaining: 5.25s\n",
      "87:\tlearn: 0.2856925\ttotal: 505ms\tremaining: 5.24s\n",
      "88:\tlearn: 0.2845606\ttotal: 511ms\tremaining: 5.23s\n",
      "89:\tlearn: 0.2832769\ttotal: 516ms\tremaining: 5.22s\n",
      "90:\tlearn: 0.2820822\ttotal: 521ms\tremaining: 5.21s\n",
      "91:\tlearn: 0.2809405\ttotal: 527ms\tremaining: 5.2s\n",
      "92:\tlearn: 0.2799328\ttotal: 531ms\tremaining: 5.18s\n",
      "93:\tlearn: 0.2788268\ttotal: 536ms\tremaining: 5.17s\n",
      "94:\tlearn: 0.2774620\ttotal: 543ms\tremaining: 5.17s\n",
      "95:\tlearn: 0.2761181\ttotal: 549ms\tremaining: 5.17s\n",
      "96:\tlearn: 0.2750691\ttotal: 555ms\tremaining: 5.17s\n",
      "97:\tlearn: 0.2741005\ttotal: 562ms\tremaining: 5.17s\n",
      "98:\tlearn: 0.2729681\ttotal: 567ms\tremaining: 5.16s\n",
      "99:\tlearn: 0.2717656\ttotal: 572ms\tremaining: 5.15s\n",
      "100:\tlearn: 0.2707347\ttotal: 578ms\tremaining: 5.14s\n",
      "101:\tlearn: 0.2697126\ttotal: 583ms\tremaining: 5.13s\n",
      "102:\tlearn: 0.2689088\ttotal: 588ms\tremaining: 5.12s\n",
      "103:\tlearn: 0.2679869\ttotal: 594ms\tremaining: 5.11s\n",
      "104:\tlearn: 0.2668850\ttotal: 599ms\tremaining: 5.1s\n",
      "105:\tlearn: 0.2655653\ttotal: 604ms\tremaining: 5.09s\n",
      "106:\tlearn: 0.2647105\ttotal: 608ms\tremaining: 5.08s\n",
      "107:\tlearn: 0.2637090\ttotal: 613ms\tremaining: 5.07s\n",
      "108:\tlearn: 0.2626507\ttotal: 618ms\tremaining: 5.05s\n",
      "109:\tlearn: 0.2616067\ttotal: 623ms\tremaining: 5.04s\n",
      "110:\tlearn: 0.2608142\ttotal: 628ms\tremaining: 5.03s\n",
      "111:\tlearn: 0.2596481\ttotal: 633ms\tremaining: 5.02s\n",
      "112:\tlearn: 0.2589492\ttotal: 638ms\tremaining: 5.01s\n",
      "113:\tlearn: 0.2582009\ttotal: 643ms\tremaining: 5s\n",
      "114:\tlearn: 0.2572569\ttotal: 648ms\tremaining: 4.99s\n",
      "115:\tlearn: 0.2561314\ttotal: 653ms\tremaining: 4.97s\n",
      "116:\tlearn: 0.2552114\ttotal: 658ms\tremaining: 4.96s\n",
      "117:\tlearn: 0.2543453\ttotal: 663ms\tremaining: 4.95s\n",
      "118:\tlearn: 0.2534363\ttotal: 668ms\tremaining: 4.94s\n",
      "119:\tlearn: 0.2526744\ttotal: 673ms\tremaining: 4.93s\n",
      "120:\tlearn: 0.2514870\ttotal: 677ms\tremaining: 4.92s\n",
      "121:\tlearn: 0.2508980\ttotal: 682ms\tremaining: 4.91s\n",
      "122:\tlearn: 0.2500867\ttotal: 687ms\tremaining: 4.9s\n",
      "123:\tlearn: 0.2495318\ttotal: 692ms\tremaining: 4.89s\n",
      "124:\tlearn: 0.2485996\ttotal: 697ms\tremaining: 4.88s\n",
      "125:\tlearn: 0.2478506\ttotal: 702ms\tremaining: 4.87s\n",
      "126:\tlearn: 0.2471042\ttotal: 707ms\tremaining: 4.86s\n",
      "127:\tlearn: 0.2461675\ttotal: 712ms\tremaining: 4.85s\n",
      "128:\tlearn: 0.2452724\ttotal: 717ms\tremaining: 4.84s\n",
      "129:\tlearn: 0.2442424\ttotal: 722ms\tremaining: 4.83s\n",
      "130:\tlearn: 0.2435105\ttotal: 728ms\tremaining: 4.83s\n",
      "131:\tlearn: 0.2426855\ttotal: 735ms\tremaining: 4.83s\n",
      "132:\tlearn: 0.2417833\ttotal: 741ms\tremaining: 4.83s\n",
      "133:\tlearn: 0.2410940\ttotal: 747ms\tremaining: 4.83s\n",
      "134:\tlearn: 0.2403790\ttotal: 752ms\tremaining: 4.82s\n",
      "135:\tlearn: 0.2397150\ttotal: 758ms\tremaining: 4.82s\n",
      "136:\tlearn: 0.2390509\ttotal: 763ms\tremaining: 4.81s\n",
      "137:\tlearn: 0.2381909\ttotal: 768ms\tremaining: 4.8s\n",
      "138:\tlearn: 0.2374643\ttotal: 773ms\tremaining: 4.79s\n",
      "139:\tlearn: 0.2366459\ttotal: 778ms\tremaining: 4.78s\n",
      "140:\tlearn: 0.2359811\ttotal: 783ms\tremaining: 4.77s\n",
      "141:\tlearn: 0.2353178\ttotal: 788ms\tremaining: 4.76s\n",
      "142:\tlearn: 0.2344739\ttotal: 793ms\tremaining: 4.75s\n",
      "143:\tlearn: 0.2339430\ttotal: 798ms\tremaining: 4.74s\n",
      "144:\tlearn: 0.2334273\ttotal: 803ms\tremaining: 4.74s\n",
      "145:\tlearn: 0.2329314\ttotal: 808ms\tremaining: 4.72s\n",
      "146:\tlearn: 0.2321876\ttotal: 813ms\tremaining: 4.72s\n",
      "147:\tlearn: 0.2314994\ttotal: 818ms\tremaining: 4.71s\n",
      "148:\tlearn: 0.2308678\ttotal: 822ms\tremaining: 4.7s\n",
      "149:\tlearn: 0.2302415\ttotal: 827ms\tremaining: 4.69s\n",
      "150:\tlearn: 0.2295237\ttotal: 832ms\tremaining: 4.68s\n",
      "151:\tlearn: 0.2289298\ttotal: 838ms\tremaining: 4.67s\n",
      "152:\tlearn: 0.2281630\ttotal: 843ms\tremaining: 4.67s\n",
      "153:\tlearn: 0.2275794\ttotal: 848ms\tremaining: 4.66s\n",
      "154:\tlearn: 0.2269677\ttotal: 853ms\tremaining: 4.65s\n",
      "155:\tlearn: 0.2262590\ttotal: 858ms\tremaining: 4.64s\n",
      "156:\tlearn: 0.2255146\ttotal: 863ms\tremaining: 4.63s\n",
      "157:\tlearn: 0.2249533\ttotal: 868ms\tremaining: 4.62s\n",
      "158:\tlearn: 0.2244053\ttotal: 872ms\tremaining: 4.61s\n",
      "159:\tlearn: 0.2237175\ttotal: 877ms\tremaining: 4.61s\n",
      "160:\tlearn: 0.2232279\ttotal: 882ms\tremaining: 4.6s\n",
      "161:\tlearn: 0.2226248\ttotal: 887ms\tremaining: 4.59s\n",
      "162:\tlearn: 0.2220590\ttotal: 892ms\tremaining: 4.58s\n",
      "163:\tlearn: 0.2211847\ttotal: 897ms\tremaining: 4.57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164:\tlearn: 0.2205087\ttotal: 903ms\tremaining: 4.57s\n",
      "165:\tlearn: 0.2198164\ttotal: 909ms\tremaining: 4.57s\n",
      "166:\tlearn: 0.2192398\ttotal: 916ms\tremaining: 4.57s\n",
      "167:\tlearn: 0.2187468\ttotal: 922ms\tremaining: 4.56s\n",
      "168:\tlearn: 0.2180737\ttotal: 928ms\tremaining: 4.56s\n",
      "169:\tlearn: 0.2176055\ttotal: 934ms\tremaining: 4.56s\n",
      "170:\tlearn: 0.2170092\ttotal: 939ms\tremaining: 4.55s\n",
      "171:\tlearn: 0.2163717\ttotal: 944ms\tremaining: 4.54s\n",
      "172:\tlearn: 0.2157998\ttotal: 950ms\tremaining: 4.54s\n",
      "173:\tlearn: 0.2152023\ttotal: 957ms\tremaining: 4.54s\n",
      "174:\tlearn: 0.2147340\ttotal: 963ms\tremaining: 4.54s\n",
      "175:\tlearn: 0.2141784\ttotal: 969ms\tremaining: 4.54s\n",
      "176:\tlearn: 0.2137185\ttotal: 978ms\tremaining: 4.55s\n",
      "177:\tlearn: 0.2132685\ttotal: 984ms\tremaining: 4.54s\n",
      "178:\tlearn: 0.2128861\ttotal: 991ms\tremaining: 4.55s\n",
      "179:\tlearn: 0.2122979\ttotal: 997ms\tremaining: 4.54s\n",
      "180:\tlearn: 0.2118690\ttotal: 1s\tremaining: 4.54s\n",
      "181:\tlearn: 0.2114954\ttotal: 1.01s\tremaining: 4.53s\n",
      "182:\tlearn: 0.2109193\ttotal: 1.01s\tremaining: 4.52s\n",
      "183:\tlearn: 0.2104531\ttotal: 1.02s\tremaining: 4.51s\n",
      "184:\tlearn: 0.2098947\ttotal: 1.02s\tremaining: 4.5s\n",
      "185:\tlearn: 0.2093989\ttotal: 1.03s\tremaining: 4.5s\n",
      "186:\tlearn: 0.2089643\ttotal: 1.03s\tremaining: 4.49s\n",
      "187:\tlearn: 0.2084514\ttotal: 1.04s\tremaining: 4.49s\n",
      "188:\tlearn: 0.2080262\ttotal: 1.04s\tremaining: 4.48s\n",
      "189:\tlearn: 0.2074018\ttotal: 1.05s\tremaining: 4.47s\n",
      "190:\tlearn: 0.2070299\ttotal: 1.05s\tremaining: 4.47s\n",
      "191:\tlearn: 0.2064993\ttotal: 1.06s\tremaining: 4.46s\n",
      "192:\tlearn: 0.2059661\ttotal: 1.06s\tremaining: 4.45s\n",
      "193:\tlearn: 0.2055601\ttotal: 1.07s\tremaining: 4.44s\n",
      "194:\tlearn: 0.2050168\ttotal: 1.07s\tremaining: 4.43s\n",
      "195:\tlearn: 0.2044832\ttotal: 1.08s\tremaining: 4.42s\n",
      "196:\tlearn: 0.2040757\ttotal: 1.08s\tremaining: 4.42s\n",
      "197:\tlearn: 0.2034631\ttotal: 1.09s\tremaining: 4.42s\n",
      "198:\tlearn: 0.2030180\ttotal: 1.1s\tremaining: 4.42s\n",
      "199:\tlearn: 0.2025437\ttotal: 1.1s\tremaining: 4.41s\n",
      "200:\tlearn: 0.2020155\ttotal: 1.11s\tremaining: 4.41s\n",
      "201:\tlearn: 0.2014482\ttotal: 1.11s\tremaining: 4.4s\n",
      "202:\tlearn: 0.2011347\ttotal: 1.12s\tremaining: 4.39s\n",
      "203:\tlearn: 0.2006730\ttotal: 1.12s\tremaining: 4.39s\n",
      "204:\tlearn: 0.2001428\ttotal: 1.13s\tremaining: 4.38s\n",
      "205:\tlearn: 0.1997065\ttotal: 1.13s\tremaining: 4.37s\n",
      "206:\tlearn: 0.1990879\ttotal: 1.14s\tremaining: 4.37s\n",
      "207:\tlearn: 0.1986119\ttotal: 1.15s\tremaining: 4.36s\n",
      "208:\tlearn: 0.1982744\ttotal: 1.15s\tremaining: 4.36s\n",
      "209:\tlearn: 0.1979223\ttotal: 1.16s\tremaining: 4.35s\n",
      "210:\tlearn: 0.1975260\ttotal: 1.16s\tremaining: 4.34s\n",
      "211:\tlearn: 0.1971080\ttotal: 1.17s\tremaining: 4.34s\n",
      "212:\tlearn: 0.1966407\ttotal: 1.17s\tremaining: 4.33s\n",
      "213:\tlearn: 0.1961414\ttotal: 1.18s\tremaining: 4.33s\n",
      "214:\tlearn: 0.1957667\ttotal: 1.18s\tremaining: 4.32s\n",
      "215:\tlearn: 0.1955043\ttotal: 1.19s\tremaining: 4.32s\n",
      "216:\tlearn: 0.1950574\ttotal: 1.2s\tremaining: 4.31s\n",
      "217:\tlearn: 0.1945396\ttotal: 1.2s\tremaining: 4.31s\n",
      "218:\tlearn: 0.1942552\ttotal: 1.21s\tremaining: 4.31s\n",
      "219:\tlearn: 0.1938858\ttotal: 1.21s\tremaining: 4.3s\n",
      "220:\tlearn: 0.1934864\ttotal: 1.22s\tremaining: 4.29s\n",
      "221:\tlearn: 0.1930966\ttotal: 1.23s\tremaining: 4.29s\n",
      "222:\tlearn: 0.1926409\ttotal: 1.23s\tremaining: 4.29s\n",
      "223:\tlearn: 0.1922950\ttotal: 1.24s\tremaining: 4.29s\n",
      "224:\tlearn: 0.1921319\ttotal: 1.24s\tremaining: 4.29s\n",
      "225:\tlearn: 0.1917461\ttotal: 1.25s\tremaining: 4.28s\n",
      "226:\tlearn: 0.1911934\ttotal: 1.26s\tremaining: 4.28s\n",
      "227:\tlearn: 0.1910128\ttotal: 1.26s\tremaining: 4.28s\n",
      "228:\tlearn: 0.1905530\ttotal: 1.27s\tremaining: 4.28s\n",
      "229:\tlearn: 0.1900895\ttotal: 1.28s\tremaining: 4.28s\n",
      "230:\tlearn: 0.1896260\ttotal: 1.28s\tremaining: 4.28s\n",
      "231:\tlearn: 0.1892054\ttotal: 1.29s\tremaining: 4.28s\n",
      "232:\tlearn: 0.1889022\ttotal: 1.3s\tremaining: 4.27s\n",
      "233:\tlearn: 0.1884636\ttotal: 1.3s\tremaining: 4.28s\n",
      "234:\tlearn: 0.1879438\ttotal: 1.31s\tremaining: 4.27s\n",
      "235:\tlearn: 0.1876059\ttotal: 1.32s\tremaining: 4.27s\n",
      "236:\tlearn: 0.1872285\ttotal: 1.32s\tremaining: 4.26s\n",
      "237:\tlearn: 0.1868849\ttotal: 1.33s\tremaining: 4.25s\n",
      "238:\tlearn: 0.1865676\ttotal: 1.34s\tremaining: 4.26s\n",
      "239:\tlearn: 0.1860734\ttotal: 1.34s\tremaining: 4.25s\n",
      "240:\tlearn: 0.1857171\ttotal: 1.35s\tremaining: 4.25s\n",
      "241:\tlearn: 0.1854404\ttotal: 1.35s\tremaining: 4.24s\n",
      "242:\tlearn: 0.1851356\ttotal: 1.36s\tremaining: 4.24s\n",
      "243:\tlearn: 0.1847101\ttotal: 1.37s\tremaining: 4.24s\n",
      "244:\tlearn: 0.1843318\ttotal: 1.37s\tremaining: 4.24s\n",
      "245:\tlearn: 0.1840007\ttotal: 1.38s\tremaining: 4.23s\n",
      "246:\tlearn: 0.1837696\ttotal: 1.39s\tremaining: 4.23s\n",
      "247:\tlearn: 0.1833149\ttotal: 1.39s\tremaining: 4.22s\n",
      "248:\tlearn: 0.1830362\ttotal: 1.4s\tremaining: 4.22s\n",
      "249:\tlearn: 0.1827414\ttotal: 1.4s\tremaining: 4.21s\n",
      "250:\tlearn: 0.1823495\ttotal: 1.41s\tremaining: 4.21s\n",
      "251:\tlearn: 0.1821018\ttotal: 1.42s\tremaining: 4.21s\n",
      "252:\tlearn: 0.1817188\ttotal: 1.42s\tremaining: 4.2s\n",
      "253:\tlearn: 0.1813352\ttotal: 1.43s\tremaining: 4.19s\n",
      "254:\tlearn: 0.1809693\ttotal: 1.43s\tremaining: 4.19s\n",
      "255:\tlearn: 0.1806616\ttotal: 1.44s\tremaining: 4.18s\n",
      "256:\tlearn: 0.1802059\ttotal: 1.45s\tremaining: 4.18s\n",
      "257:\tlearn: 0.1798350\ttotal: 1.45s\tremaining: 4.18s\n",
      "258:\tlearn: 0.1795423\ttotal: 1.46s\tremaining: 4.17s\n",
      "259:\tlearn: 0.1792282\ttotal: 1.46s\tremaining: 4.17s\n",
      "260:\tlearn: 0.1789164\ttotal: 1.47s\tremaining: 4.17s\n",
      "261:\tlearn: 0.1785967\ttotal: 1.48s\tremaining: 4.17s\n",
      "262:\tlearn: 0.1782558\ttotal: 1.48s\tremaining: 4.16s\n",
      "263:\tlearn: 0.1778689\ttotal: 1.49s\tremaining: 4.15s\n",
      "264:\tlearn: 0.1776106\ttotal: 1.49s\tremaining: 4.15s\n",
      "265:\tlearn: 0.1773285\ttotal: 1.5s\tremaining: 4.14s\n",
      "266:\tlearn: 0.1771350\ttotal: 1.5s\tremaining: 4.13s\n",
      "267:\tlearn: 0.1768689\ttotal: 1.51s\tremaining: 4.12s\n",
      "268:\tlearn: 0.1765449\ttotal: 1.51s\tremaining: 4.12s\n",
      "269:\tlearn: 0.1763132\ttotal: 1.52s\tremaining: 4.11s\n",
      "270:\tlearn: 0.1759873\ttotal: 1.52s\tremaining: 4.1s\n",
      "271:\tlearn: 0.1756574\ttotal: 1.53s\tremaining: 4.09s\n",
      "272:\tlearn: 0.1753187\ttotal: 1.53s\tremaining: 4.08s\n",
      "273:\tlearn: 0.1750798\ttotal: 1.54s\tremaining: 4.08s\n",
      "274:\tlearn: 0.1747668\ttotal: 1.54s\tremaining: 4.07s\n",
      "275:\tlearn: 0.1744717\ttotal: 1.55s\tremaining: 4.06s\n",
      "276:\tlearn: 0.1741205\ttotal: 1.55s\tremaining: 4.06s\n",
      "277:\tlearn: 0.1738614\ttotal: 1.56s\tremaining: 4.05s\n",
      "278:\tlearn: 0.1734961\ttotal: 1.56s\tremaining: 4.04s\n",
      "279:\tlearn: 0.1732718\ttotal: 1.57s\tremaining: 4.03s\n",
      "280:\tlearn: 0.1730116\ttotal: 1.57s\tremaining: 4.03s\n",
      "281:\tlearn: 0.1726351\ttotal: 1.58s\tremaining: 4.02s\n",
      "282:\tlearn: 0.1723674\ttotal: 1.58s\tremaining: 4.01s\n",
      "283:\tlearn: 0.1720847\ttotal: 1.59s\tremaining: 4s\n",
      "284:\tlearn: 0.1717134\ttotal: 1.59s\tremaining: 4s\n",
      "285:\tlearn: 0.1714345\ttotal: 1.6s\tremaining: 3.99s\n",
      "286:\tlearn: 0.1710032\ttotal: 1.6s\tremaining: 3.98s\n",
      "287:\tlearn: 0.1707580\ttotal: 1.61s\tremaining: 3.98s\n",
      "288:\tlearn: 0.1703778\ttotal: 1.61s\tremaining: 3.97s\n",
      "289:\tlearn: 0.1700034\ttotal: 1.62s\tremaining: 3.96s\n",
      "290:\tlearn: 0.1695125\ttotal: 1.62s\tremaining: 3.96s\n",
      "291:\tlearn: 0.1692384\ttotal: 1.63s\tremaining: 3.95s\n",
      "292:\tlearn: 0.1688712\ttotal: 1.64s\tremaining: 3.95s\n",
      "293:\tlearn: 0.1685339\ttotal: 1.64s\tremaining: 3.94s\n",
      "294:\tlearn: 0.1682979\ttotal: 1.65s\tremaining: 3.94s\n",
      "295:\tlearn: 0.1678578\ttotal: 1.65s\tremaining: 3.93s\n",
      "296:\tlearn: 0.1676209\ttotal: 1.66s\tremaining: 3.92s\n",
      "297:\tlearn: 0.1673137\ttotal: 1.66s\tremaining: 3.92s\n",
      "298:\tlearn: 0.1671124\ttotal: 1.67s\tremaining: 3.91s\n",
      "299:\tlearn: 0.1668686\ttotal: 1.67s\tremaining: 3.9s\n",
      "300:\tlearn: 0.1666085\ttotal: 1.68s\tremaining: 3.9s\n",
      "301:\tlearn: 0.1663944\ttotal: 1.68s\tremaining: 3.89s\n",
      "302:\tlearn: 0.1660819\ttotal: 1.69s\tremaining: 3.88s\n",
      "303:\tlearn: 0.1658635\ttotal: 1.69s\tremaining: 3.88s\n",
      "304:\tlearn: 0.1656066\ttotal: 1.7s\tremaining: 3.88s\n",
      "305:\tlearn: 0.1652895\ttotal: 1.71s\tremaining: 3.87s\n",
      "306:\tlearn: 0.1650709\ttotal: 1.71s\tremaining: 3.87s\n",
      "307:\tlearn: 0.1647302\ttotal: 1.72s\tremaining: 3.86s\n",
      "308:\tlearn: 0.1644028\ttotal: 1.72s\tremaining: 3.86s\n",
      "309:\tlearn: 0.1641618\ttotal: 1.73s\tremaining: 3.85s\n",
      "310:\tlearn: 0.1639186\ttotal: 1.74s\tremaining: 3.85s\n",
      "311:\tlearn: 0.1636835\ttotal: 1.74s\tremaining: 3.84s\n",
      "312:\tlearn: 0.1633694\ttotal: 1.75s\tremaining: 3.84s\n",
      "313:\tlearn: 0.1630464\ttotal: 1.75s\tremaining: 3.83s\n",
      "314:\tlearn: 0.1626910\ttotal: 1.76s\tremaining: 3.83s\n",
      "315:\tlearn: 0.1625183\ttotal: 1.76s\tremaining: 3.82s\n",
      "316:\tlearn: 0.1623346\ttotal: 1.77s\tremaining: 3.82s\n",
      "317:\tlearn: 0.1620141\ttotal: 1.78s\tremaining: 3.81s\n",
      "318:\tlearn: 0.1616969\ttotal: 1.78s\tremaining: 3.81s\n",
      "319:\tlearn: 0.1612860\ttotal: 1.79s\tremaining: 3.81s\n",
      "320:\tlearn: 0.1610531\ttotal: 1.8s\tremaining: 3.8s\n",
      "321:\tlearn: 0.1608322\ttotal: 1.8s\tremaining: 3.79s\n",
      "322:\tlearn: 0.1606023\ttotal: 1.81s\tremaining: 3.79s\n",
      "323:\tlearn: 0.1603659\ttotal: 1.82s\tremaining: 3.79s\n",
      "324:\tlearn: 0.1599436\ttotal: 1.82s\tremaining: 3.79s\n",
      "325:\tlearn: 0.1595494\ttotal: 1.83s\tremaining: 3.79s\n",
      "326:\tlearn: 0.1593637\ttotal: 1.84s\tremaining: 3.78s\n",
      "327:\tlearn: 0.1591457\ttotal: 1.84s\tremaining: 3.78s\n",
      "328:\tlearn: 0.1587631\ttotal: 1.85s\tremaining: 3.78s\n",
      "329:\tlearn: 0.1585160\ttotal: 1.86s\tremaining: 3.77s\n",
      "330:\tlearn: 0.1582206\ttotal: 1.86s\tremaining: 3.77s\n",
      "331:\tlearn: 0.1578272\ttotal: 1.87s\tremaining: 3.76s\n",
      "332:\tlearn: 0.1576305\ttotal: 1.87s\tremaining: 3.75s\n",
      "333:\tlearn: 0.1572989\ttotal: 1.88s\tremaining: 3.74s\n",
      "334:\tlearn: 0.1570147\ttotal: 1.88s\tremaining: 3.74s\n",
      "335:\tlearn: 0.1567145\ttotal: 1.89s\tremaining: 3.73s\n",
      "336:\tlearn: 0.1564470\ttotal: 1.89s\tremaining: 3.72s\n",
      "337:\tlearn: 0.1561654\ttotal: 1.9s\tremaining: 3.72s\n",
      "338:\tlearn: 0.1558688\ttotal: 1.9s\tremaining: 3.71s\n",
      "339:\tlearn: 0.1556760\ttotal: 1.91s\tremaining: 3.7s\n",
      "340:\tlearn: 0.1554051\ttotal: 1.91s\tremaining: 3.69s\n",
      "341:\tlearn: 0.1551596\ttotal: 1.92s\tremaining: 3.69s\n",
      "342:\tlearn: 0.1548622\ttotal: 1.92s\tremaining: 3.68s\n",
      "343:\tlearn: 0.1546169\ttotal: 1.93s\tremaining: 3.67s\n",
      "344:\tlearn: 0.1542537\ttotal: 1.93s\tremaining: 3.67s\n",
      "345:\tlearn: 0.1540130\ttotal: 1.94s\tremaining: 3.66s\n",
      "346:\tlearn: 0.1537633\ttotal: 1.94s\tremaining: 3.65s\n",
      "347:\tlearn: 0.1534741\ttotal: 1.95s\tremaining: 3.65s\n",
      "348:\tlearn: 0.1531262\ttotal: 1.95s\tremaining: 3.64s\n",
      "349:\tlearn: 0.1528611\ttotal: 1.96s\tremaining: 3.63s\n",
      "350:\tlearn: 0.1525752\ttotal: 1.96s\tremaining: 3.63s\n",
      "351:\tlearn: 0.1522921\ttotal: 1.97s\tremaining: 3.62s\n",
      "352:\tlearn: 0.1521172\ttotal: 1.97s\tremaining: 3.61s\n",
      "353:\tlearn: 0.1517918\ttotal: 1.98s\tremaining: 3.61s\n",
      "354:\tlearn: 0.1515405\ttotal: 1.98s\tremaining: 3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355:\tlearn: 0.1512416\ttotal: 1.99s\tremaining: 3.6s\n",
      "356:\tlearn: 0.1509338\ttotal: 2s\tremaining: 3.6s\n",
      "357:\tlearn: 0.1506038\ttotal: 2s\tremaining: 3.59s\n",
      "358:\tlearn: 0.1503911\ttotal: 2.01s\tremaining: 3.59s\n",
      "359:\tlearn: 0.1501706\ttotal: 2.02s\tremaining: 3.58s\n",
      "360:\tlearn: 0.1500036\ttotal: 2.02s\tremaining: 3.58s\n",
      "361:\tlearn: 0.1497818\ttotal: 2.03s\tremaining: 3.58s\n",
      "362:\tlearn: 0.1495022\ttotal: 2.03s\tremaining: 3.57s\n",
      "363:\tlearn: 0.1493201\ttotal: 2.04s\tremaining: 3.56s\n",
      "364:\tlearn: 0.1490602\ttotal: 2.04s\tremaining: 3.56s\n",
      "365:\tlearn: 0.1488126\ttotal: 2.05s\tremaining: 3.55s\n",
      "366:\tlearn: 0.1485137\ttotal: 2.05s\tremaining: 3.54s\n",
      "367:\tlearn: 0.1483581\ttotal: 2.06s\tremaining: 3.54s\n",
      "368:\tlearn: 0.1481860\ttotal: 2.06s\tremaining: 3.53s\n",
      "369:\tlearn: 0.1479045\ttotal: 2.07s\tremaining: 3.52s\n",
      "370:\tlearn: 0.1476412\ttotal: 2.08s\tremaining: 3.52s\n",
      "371:\tlearn: 0.1474438\ttotal: 2.08s\tremaining: 3.52s\n",
      "372:\tlearn: 0.1471669\ttotal: 2.09s\tremaining: 3.51s\n",
      "373:\tlearn: 0.1469390\ttotal: 2.09s\tremaining: 3.5s\n",
      "374:\tlearn: 0.1466813\ttotal: 2.1s\tremaining: 3.5s\n",
      "375:\tlearn: 0.1463324\ttotal: 2.1s\tremaining: 3.49s\n",
      "376:\tlearn: 0.1461690\ttotal: 2.11s\tremaining: 3.49s\n",
      "377:\tlearn: 0.1459144\ttotal: 2.12s\tremaining: 3.48s\n",
      "378:\tlearn: 0.1457439\ttotal: 2.12s\tremaining: 3.48s\n",
      "379:\tlearn: 0.1455378\ttotal: 2.13s\tremaining: 3.47s\n",
      "380:\tlearn: 0.1453149\ttotal: 2.13s\tremaining: 3.47s\n",
      "381:\tlearn: 0.1450644\ttotal: 2.14s\tremaining: 3.46s\n",
      "382:\tlearn: 0.1448261\ttotal: 2.15s\tremaining: 3.46s\n",
      "383:\tlearn: 0.1445886\ttotal: 2.15s\tremaining: 3.45s\n",
      "384:\tlearn: 0.1443467\ttotal: 2.16s\tremaining: 3.45s\n",
      "385:\tlearn: 0.1441429\ttotal: 2.16s\tremaining: 3.44s\n",
      "386:\tlearn: 0.1438406\ttotal: 2.17s\tremaining: 3.44s\n",
      "387:\tlearn: 0.1436716\ttotal: 2.18s\tremaining: 3.43s\n",
      "388:\tlearn: 0.1433581\ttotal: 2.19s\tremaining: 3.43s\n",
      "389:\tlearn: 0.1430716\ttotal: 2.19s\tremaining: 3.43s\n",
      "390:\tlearn: 0.1428694\ttotal: 2.19s\tremaining: 3.42s\n",
      "391:\tlearn: 0.1426106\ttotal: 2.2s\tremaining: 3.41s\n",
      "392:\tlearn: 0.1424187\ttotal: 2.21s\tremaining: 3.41s\n",
      "393:\tlearn: 0.1421689\ttotal: 2.21s\tremaining: 3.4s\n",
      "394:\tlearn: 0.1419813\ttotal: 2.22s\tremaining: 3.39s\n",
      "395:\tlearn: 0.1417620\ttotal: 2.22s\tremaining: 3.39s\n",
      "396:\tlearn: 0.1415255\ttotal: 2.23s\tremaining: 3.38s\n",
      "397:\tlearn: 0.1412373\ttotal: 2.23s\tremaining: 3.38s\n",
      "398:\tlearn: 0.1410398\ttotal: 2.24s\tremaining: 3.37s\n",
      "399:\tlearn: 0.1408898\ttotal: 2.24s\tremaining: 3.37s\n",
      "400:\tlearn: 0.1406741\ttotal: 2.25s\tremaining: 3.36s\n",
      "401:\tlearn: 0.1404333\ttotal: 2.26s\tremaining: 3.36s\n",
      "402:\tlearn: 0.1401803\ttotal: 2.27s\tremaining: 3.36s\n",
      "403:\tlearn: 0.1399535\ttotal: 2.27s\tremaining: 3.35s\n",
      "404:\tlearn: 0.1397553\ttotal: 2.28s\tremaining: 3.35s\n",
      "405:\tlearn: 0.1395581\ttotal: 2.29s\tremaining: 3.35s\n",
      "406:\tlearn: 0.1392411\ttotal: 2.29s\tremaining: 3.34s\n",
      "407:\tlearn: 0.1389651\ttotal: 2.3s\tremaining: 3.34s\n",
      "408:\tlearn: 0.1387554\ttotal: 2.31s\tremaining: 3.33s\n",
      "409:\tlearn: 0.1385548\ttotal: 2.31s\tremaining: 3.33s\n",
      "410:\tlearn: 0.1382925\ttotal: 2.32s\tremaining: 3.33s\n",
      "411:\tlearn: 0.1379563\ttotal: 2.33s\tremaining: 3.32s\n",
      "412:\tlearn: 0.1377304\ttotal: 2.33s\tremaining: 3.32s\n",
      "413:\tlearn: 0.1373504\ttotal: 2.34s\tremaining: 3.31s\n",
      "414:\tlearn: 0.1370799\ttotal: 2.35s\tremaining: 3.31s\n",
      "415:\tlearn: 0.1368433\ttotal: 2.36s\tremaining: 3.31s\n",
      "416:\tlearn: 0.1365305\ttotal: 2.37s\tremaining: 3.31s\n",
      "417:\tlearn: 0.1363143\ttotal: 2.37s\tremaining: 3.3s\n",
      "418:\tlearn: 0.1361367\ttotal: 2.38s\tremaining: 3.3s\n",
      "419:\tlearn: 0.1358144\ttotal: 2.39s\tremaining: 3.3s\n",
      "420:\tlearn: 0.1355201\ttotal: 2.4s\tremaining: 3.3s\n",
      "421:\tlearn: 0.1351778\ttotal: 2.4s\tremaining: 3.29s\n",
      "422:\tlearn: 0.1349363\ttotal: 2.41s\tremaining: 3.29s\n",
      "423:\tlearn: 0.1347016\ttotal: 2.42s\tremaining: 3.29s\n",
      "424:\tlearn: 0.1345127\ttotal: 2.43s\tremaining: 3.28s\n",
      "425:\tlearn: 0.1342948\ttotal: 2.44s\tremaining: 3.28s\n",
      "426:\tlearn: 0.1340733\ttotal: 2.45s\tremaining: 3.29s\n",
      "427:\tlearn: 0.1338976\ttotal: 2.46s\tremaining: 3.28s\n",
      "428:\tlearn: 0.1336414\ttotal: 2.47s\tremaining: 3.28s\n",
      "429:\tlearn: 0.1334091\ttotal: 2.47s\tremaining: 3.28s\n",
      "430:\tlearn: 0.1332328\ttotal: 2.48s\tremaining: 3.27s\n",
      "431:\tlearn: 0.1330627\ttotal: 2.48s\tremaining: 3.27s\n",
      "432:\tlearn: 0.1328280\ttotal: 2.49s\tremaining: 3.26s\n",
      "433:\tlearn: 0.1325857\ttotal: 2.5s\tremaining: 3.25s\n",
      "434:\tlearn: 0.1323549\ttotal: 2.5s\tremaining: 3.25s\n",
      "435:\tlearn: 0.1321768\ttotal: 2.51s\tremaining: 3.24s\n",
      "436:\tlearn: 0.1319946\ttotal: 2.51s\tremaining: 3.23s\n",
      "437:\tlearn: 0.1318604\ttotal: 2.52s\tremaining: 3.23s\n",
      "438:\tlearn: 0.1316331\ttotal: 2.52s\tremaining: 3.22s\n",
      "439:\tlearn: 0.1314213\ttotal: 2.53s\tremaining: 3.22s\n",
      "440:\tlearn: 0.1312653\ttotal: 2.53s\tremaining: 3.21s\n",
      "441:\tlearn: 0.1311072\ttotal: 2.54s\tremaining: 3.21s\n",
      "442:\tlearn: 0.1308971\ttotal: 2.54s\tremaining: 3.2s\n",
      "443:\tlearn: 0.1306352\ttotal: 2.55s\tremaining: 3.19s\n",
      "444:\tlearn: 0.1303881\ttotal: 2.56s\tremaining: 3.19s\n",
      "445:\tlearn: 0.1302508\ttotal: 2.56s\tremaining: 3.19s\n",
      "446:\tlearn: 0.1300287\ttotal: 2.57s\tremaining: 3.18s\n",
      "447:\tlearn: 0.1298248\ttotal: 2.58s\tremaining: 3.18s\n",
      "448:\tlearn: 0.1296117\ttotal: 2.58s\tremaining: 3.17s\n",
      "449:\tlearn: 0.1294009\ttotal: 2.59s\tremaining: 3.17s\n",
      "450:\tlearn: 0.1291676\ttotal: 2.6s\tremaining: 3.16s\n",
      "451:\tlearn: 0.1288644\ttotal: 2.6s\tremaining: 3.15s\n",
      "452:\tlearn: 0.1286137\ttotal: 2.61s\tremaining: 3.15s\n",
      "453:\tlearn: 0.1283463\ttotal: 2.61s\tremaining: 3.14s\n",
      "454:\tlearn: 0.1281210\ttotal: 2.62s\tremaining: 3.13s\n",
      "455:\tlearn: 0.1279243\ttotal: 2.62s\tremaining: 3.13s\n",
      "456:\tlearn: 0.1277497\ttotal: 2.63s\tremaining: 3.12s\n",
      "457:\tlearn: 0.1275646\ttotal: 2.63s\tremaining: 3.11s\n",
      "458:\tlearn: 0.1272373\ttotal: 2.64s\tremaining: 3.11s\n",
      "459:\tlearn: 0.1270421\ttotal: 2.64s\tremaining: 3.1s\n",
      "460:\tlearn: 0.1268154\ttotal: 2.65s\tremaining: 3.1s\n",
      "461:\tlearn: 0.1266648\ttotal: 2.65s\tremaining: 3.09s\n",
      "462:\tlearn: 0.1264619\ttotal: 2.66s\tremaining: 3.08s\n",
      "463:\tlearn: 0.1262066\ttotal: 2.66s\tremaining: 3.08s\n",
      "464:\tlearn: 0.1260067\ttotal: 2.67s\tremaining: 3.07s\n",
      "465:\tlearn: 0.1258115\ttotal: 2.68s\tremaining: 3.07s\n",
      "466:\tlearn: 0.1256127\ttotal: 2.68s\tremaining: 3.06s\n",
      "467:\tlearn: 0.1254026\ttotal: 2.69s\tremaining: 3.06s\n",
      "468:\tlearn: 0.1252025\ttotal: 2.7s\tremaining: 3.05s\n",
      "469:\tlearn: 0.1250114\ttotal: 2.71s\tremaining: 3.05s\n",
      "470:\tlearn: 0.1248012\ttotal: 2.71s\tremaining: 3.05s\n",
      "471:\tlearn: 0.1246355\ttotal: 2.72s\tremaining: 3.04s\n",
      "472:\tlearn: 0.1244295\ttotal: 2.73s\tremaining: 3.04s\n",
      "473:\tlearn: 0.1242431\ttotal: 2.74s\tremaining: 3.04s\n",
      "474:\tlearn: 0.1240494\ttotal: 2.74s\tremaining: 3.03s\n",
      "475:\tlearn: 0.1237794\ttotal: 2.75s\tremaining: 3.03s\n",
      "476:\tlearn: 0.1235048\ttotal: 2.76s\tremaining: 3.03s\n",
      "477:\tlearn: 0.1231699\ttotal: 2.77s\tremaining: 3.02s\n",
      "478:\tlearn: 0.1229957\ttotal: 2.77s\tremaining: 3.02s\n",
      "479:\tlearn: 0.1227928\ttotal: 2.78s\tremaining: 3.02s\n",
      "480:\tlearn: 0.1226142\ttotal: 2.79s\tremaining: 3.01s\n",
      "481:\tlearn: 0.1224413\ttotal: 2.8s\tremaining: 3.01s\n",
      "482:\tlearn: 0.1222979\ttotal: 2.81s\tremaining: 3s\n",
      "483:\tlearn: 0.1221067\ttotal: 2.81s\tremaining: 3s\n",
      "484:\tlearn: 0.1219646\ttotal: 2.82s\tremaining: 2.99s\n",
      "485:\tlearn: 0.1217395\ttotal: 2.83s\tremaining: 2.99s\n",
      "486:\tlearn: 0.1214882\ttotal: 2.83s\tremaining: 2.98s\n",
      "487:\tlearn: 0.1212786\ttotal: 2.84s\tremaining: 2.98s\n",
      "488:\tlearn: 0.1211047\ttotal: 2.85s\tremaining: 2.98s\n",
      "489:\tlearn: 0.1208860\ttotal: 2.85s\tremaining: 2.97s\n",
      "490:\tlearn: 0.1206929\ttotal: 2.86s\tremaining: 2.97s\n",
      "491:\tlearn: 0.1205572\ttotal: 2.87s\tremaining: 2.96s\n",
      "492:\tlearn: 0.1204175\ttotal: 2.87s\tremaining: 2.95s\n",
      "493:\tlearn: 0.1202357\ttotal: 2.88s\tremaining: 2.95s\n",
      "494:\tlearn: 0.1200032\ttotal: 2.88s\tremaining: 2.94s\n",
      "495:\tlearn: 0.1198605\ttotal: 2.89s\tremaining: 2.94s\n",
      "496:\tlearn: 0.1197221\ttotal: 2.9s\tremaining: 2.93s\n",
      "497:\tlearn: 0.1195574\ttotal: 2.9s\tremaining: 2.92s\n",
      "498:\tlearn: 0.1193742\ttotal: 2.91s\tremaining: 2.92s\n",
      "499:\tlearn: 0.1191982\ttotal: 2.92s\tremaining: 2.92s\n",
      "500:\tlearn: 0.1190084\ttotal: 2.92s\tremaining: 2.91s\n",
      "501:\tlearn: 0.1188340\ttotal: 2.93s\tremaining: 2.9s\n",
      "502:\tlearn: 0.1186245\ttotal: 2.93s\tremaining: 2.9s\n",
      "503:\tlearn: 0.1184439\ttotal: 2.94s\tremaining: 2.89s\n",
      "504:\tlearn: 0.1181779\ttotal: 2.94s\tremaining: 2.89s\n",
      "505:\tlearn: 0.1179967\ttotal: 2.95s\tremaining: 2.88s\n",
      "506:\tlearn: 0.1177946\ttotal: 2.96s\tremaining: 2.87s\n",
      "507:\tlearn: 0.1176319\ttotal: 2.96s\tremaining: 2.87s\n",
      "508:\tlearn: 0.1174752\ttotal: 2.97s\tremaining: 2.86s\n",
      "509:\tlearn: 0.1171850\ttotal: 2.97s\tremaining: 2.85s\n",
      "510:\tlearn: 0.1170332\ttotal: 2.98s\tremaining: 2.85s\n",
      "511:\tlearn: 0.1169075\ttotal: 2.98s\tremaining: 2.84s\n",
      "512:\tlearn: 0.1167185\ttotal: 2.98s\tremaining: 2.83s\n",
      "513:\tlearn: 0.1165716\ttotal: 2.99s\tremaining: 2.83s\n",
      "514:\tlearn: 0.1164028\ttotal: 3s\tremaining: 2.82s\n",
      "515:\tlearn: 0.1162092\ttotal: 3s\tremaining: 2.81s\n",
      "516:\tlearn: 0.1159890\ttotal: 3.01s\tremaining: 2.81s\n",
      "517:\tlearn: 0.1157927\ttotal: 3.01s\tremaining: 2.8s\n",
      "518:\tlearn: 0.1156090\ttotal: 3.02s\tremaining: 2.8s\n",
      "519:\tlearn: 0.1154537\ttotal: 3.02s\tremaining: 2.79s\n",
      "520:\tlearn: 0.1152675\ttotal: 3.03s\tremaining: 2.79s\n",
      "521:\tlearn: 0.1150722\ttotal: 3.03s\tremaining: 2.78s\n",
      "522:\tlearn: 0.1149208\ttotal: 3.04s\tremaining: 2.77s\n",
      "523:\tlearn: 0.1147711\ttotal: 3.05s\tremaining: 2.77s\n",
      "524:\tlearn: 0.1145984\ttotal: 3.06s\tremaining: 2.76s\n",
      "525:\tlearn: 0.1144666\ttotal: 3.06s\tremaining: 2.76s\n",
      "526:\tlearn: 0.1142963\ttotal: 3.07s\tremaining: 2.76s\n",
      "527:\tlearn: 0.1141628\ttotal: 3.08s\tremaining: 2.75s\n",
      "528:\tlearn: 0.1139857\ttotal: 3.08s\tremaining: 2.75s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529:\tlearn: 0.1137883\ttotal: 3.09s\tremaining: 2.74s\n",
      "530:\tlearn: 0.1136507\ttotal: 3.1s\tremaining: 2.73s\n",
      "531:\tlearn: 0.1134399\ttotal: 3.1s\tremaining: 2.73s\n",
      "532:\tlearn: 0.1132484\ttotal: 3.11s\tremaining: 2.73s\n",
      "533:\tlearn: 0.1130619\ttotal: 3.12s\tremaining: 2.72s\n",
      "534:\tlearn: 0.1128792\ttotal: 3.13s\tremaining: 2.72s\n",
      "535:\tlearn: 0.1127181\ttotal: 3.14s\tremaining: 2.72s\n",
      "536:\tlearn: 0.1124902\ttotal: 3.14s\tremaining: 2.71s\n",
      "537:\tlearn: 0.1123276\ttotal: 3.15s\tremaining: 2.71s\n",
      "538:\tlearn: 0.1121759\ttotal: 3.16s\tremaining: 2.7s\n",
      "539:\tlearn: 0.1120182\ttotal: 3.17s\tremaining: 2.7s\n",
      "540:\tlearn: 0.1117113\ttotal: 3.17s\tremaining: 2.69s\n",
      "541:\tlearn: 0.1115914\ttotal: 3.18s\tremaining: 2.69s\n",
      "542:\tlearn: 0.1113936\ttotal: 3.19s\tremaining: 2.68s\n",
      "543:\tlearn: 0.1111584\ttotal: 3.19s\tremaining: 2.68s\n",
      "544:\tlearn: 0.1110020\ttotal: 3.2s\tremaining: 2.67s\n",
      "545:\tlearn: 0.1108035\ttotal: 3.21s\tremaining: 2.67s\n",
      "546:\tlearn: 0.1106074\ttotal: 3.22s\tremaining: 2.66s\n",
      "547:\tlearn: 0.1104417\ttotal: 3.22s\tremaining: 2.66s\n",
      "548:\tlearn: 0.1102914\ttotal: 3.23s\tremaining: 2.65s\n",
      "549:\tlearn: 0.1101404\ttotal: 3.23s\tremaining: 2.65s\n",
      "550:\tlearn: 0.1100011\ttotal: 3.24s\tremaining: 2.64s\n",
      "551:\tlearn: 0.1098498\ttotal: 3.25s\tremaining: 2.63s\n",
      "552:\tlearn: 0.1096981\ttotal: 3.25s\tremaining: 2.63s\n",
      "553:\tlearn: 0.1094698\ttotal: 3.26s\tremaining: 2.62s\n",
      "554:\tlearn: 0.1093502\ttotal: 3.26s\tremaining: 2.62s\n",
      "555:\tlearn: 0.1091812\ttotal: 3.27s\tremaining: 2.61s\n",
      "556:\tlearn: 0.1090164\ttotal: 3.27s\tremaining: 2.6s\n",
      "557:\tlearn: 0.1088414\ttotal: 3.28s\tremaining: 2.6s\n",
      "558:\tlearn: 0.1087061\ttotal: 3.29s\tremaining: 2.6s\n",
      "559:\tlearn: 0.1085378\ttotal: 3.3s\tremaining: 2.59s\n",
      "560:\tlearn: 0.1083162\ttotal: 3.3s\tremaining: 2.58s\n",
      "561:\tlearn: 0.1081296\ttotal: 3.31s\tremaining: 2.58s\n",
      "562:\tlearn: 0.1079855\ttotal: 3.31s\tremaining: 2.57s\n",
      "563:\tlearn: 0.1079000\ttotal: 3.32s\tremaining: 2.56s\n",
      "564:\tlearn: 0.1077367\ttotal: 3.32s\tremaining: 2.56s\n",
      "565:\tlearn: 0.1075272\ttotal: 3.33s\tremaining: 2.55s\n",
      "566:\tlearn: 0.1073425\ttotal: 3.33s\tremaining: 2.54s\n",
      "567:\tlearn: 0.1071776\ttotal: 3.34s\tremaining: 2.54s\n",
      "568:\tlearn: 0.1070434\ttotal: 3.34s\tremaining: 2.53s\n",
      "569:\tlearn: 0.1069018\ttotal: 3.35s\tremaining: 2.53s\n",
      "570:\tlearn: 0.1067657\ttotal: 3.35s\tremaining: 2.52s\n",
      "571:\tlearn: 0.1065495\ttotal: 3.36s\tremaining: 2.51s\n",
      "572:\tlearn: 0.1064187\ttotal: 3.36s\tremaining: 2.51s\n",
      "573:\tlearn: 0.1062591\ttotal: 3.37s\tremaining: 2.5s\n",
      "574:\tlearn: 0.1061324\ttotal: 3.37s\tremaining: 2.49s\n",
      "575:\tlearn: 0.1059315\ttotal: 3.38s\tremaining: 2.49s\n",
      "576:\tlearn: 0.1058005\ttotal: 3.39s\tremaining: 2.48s\n",
      "577:\tlearn: 0.1056291\ttotal: 3.4s\tremaining: 2.48s\n",
      "578:\tlearn: 0.1054819\ttotal: 3.41s\tremaining: 2.48s\n",
      "579:\tlearn: 0.1053243\ttotal: 3.42s\tremaining: 2.47s\n",
      "580:\tlearn: 0.1050923\ttotal: 3.42s\tremaining: 2.47s\n",
      "581:\tlearn: 0.1049764\ttotal: 3.43s\tremaining: 2.46s\n",
      "582:\tlearn: 0.1047726\ttotal: 3.44s\tremaining: 2.46s\n",
      "583:\tlearn: 0.1045743\ttotal: 3.44s\tremaining: 2.45s\n",
      "584:\tlearn: 0.1044237\ttotal: 3.45s\tremaining: 2.45s\n",
      "585:\tlearn: 0.1043245\ttotal: 3.46s\tremaining: 2.44s\n",
      "586:\tlearn: 0.1041530\ttotal: 3.46s\tremaining: 2.44s\n",
      "587:\tlearn: 0.1039755\ttotal: 3.47s\tremaining: 2.43s\n",
      "588:\tlearn: 0.1038353\ttotal: 3.48s\tremaining: 2.43s\n",
      "589:\tlearn: 0.1036967\ttotal: 3.48s\tremaining: 2.42s\n",
      "590:\tlearn: 0.1035538\ttotal: 3.5s\tremaining: 2.42s\n",
      "591:\tlearn: 0.1034230\ttotal: 3.51s\tremaining: 2.42s\n",
      "592:\tlearn: 0.1032370\ttotal: 3.51s\tremaining: 2.41s\n",
      "593:\tlearn: 0.1030212\ttotal: 3.52s\tremaining: 2.41s\n",
      "594:\tlearn: 0.1028610\ttotal: 3.53s\tremaining: 2.4s\n",
      "595:\tlearn: 0.1027259\ttotal: 3.54s\tremaining: 2.4s\n",
      "596:\tlearn: 0.1025968\ttotal: 3.55s\tremaining: 2.4s\n",
      "597:\tlearn: 0.1023859\ttotal: 3.56s\tremaining: 2.39s\n",
      "598:\tlearn: 0.1022287\ttotal: 3.57s\tremaining: 2.39s\n",
      "599:\tlearn: 0.1020963\ttotal: 3.57s\tremaining: 2.38s\n",
      "600:\tlearn: 0.1019411\ttotal: 3.58s\tremaining: 2.38s\n",
      "601:\tlearn: 0.1017954\ttotal: 3.59s\tremaining: 2.37s\n",
      "602:\tlearn: 0.1016465\ttotal: 3.59s\tremaining: 2.37s\n",
      "603:\tlearn: 0.1015393\ttotal: 3.6s\tremaining: 2.36s\n",
      "604:\tlearn: 0.1013893\ttotal: 3.6s\tremaining: 2.35s\n",
      "605:\tlearn: 0.1012480\ttotal: 3.61s\tremaining: 2.35s\n",
      "606:\tlearn: 0.1011295\ttotal: 3.62s\tremaining: 2.34s\n",
      "607:\tlearn: 0.1009805\ttotal: 3.62s\tremaining: 2.34s\n",
      "608:\tlearn: 0.1008766\ttotal: 3.63s\tremaining: 2.33s\n",
      "609:\tlearn: 0.1007602\ttotal: 3.64s\tremaining: 2.33s\n",
      "610:\tlearn: 0.1006206\ttotal: 3.64s\tremaining: 2.32s\n",
      "611:\tlearn: 0.1004224\ttotal: 3.65s\tremaining: 2.31s\n",
      "612:\tlearn: 0.1002943\ttotal: 3.66s\tremaining: 2.31s\n",
      "613:\tlearn: 0.1001841\ttotal: 3.67s\tremaining: 2.31s\n",
      "614:\tlearn: 0.1000766\ttotal: 3.67s\tremaining: 2.3s\n",
      "615:\tlearn: 0.0999492\ttotal: 3.68s\tremaining: 2.29s\n",
      "616:\tlearn: 0.0997950\ttotal: 3.69s\tremaining: 2.29s\n",
      "617:\tlearn: 0.0996562\ttotal: 3.69s\tremaining: 2.28s\n",
      "618:\tlearn: 0.0995257\ttotal: 3.7s\tremaining: 2.28s\n",
      "619:\tlearn: 0.0993391\ttotal: 3.71s\tremaining: 2.27s\n",
      "620:\tlearn: 0.0992172\ttotal: 3.71s\tremaining: 2.27s\n",
      "621:\tlearn: 0.0990237\ttotal: 3.72s\tremaining: 2.26s\n",
      "622:\tlearn: 0.0989002\ttotal: 3.72s\tremaining: 2.25s\n",
      "623:\tlearn: 0.0987466\ttotal: 3.73s\tremaining: 2.25s\n",
      "624:\tlearn: 0.0986098\ttotal: 3.73s\tremaining: 2.24s\n",
      "625:\tlearn: 0.0984725\ttotal: 3.74s\tremaining: 2.23s\n",
      "626:\tlearn: 0.0983054\ttotal: 3.75s\tremaining: 2.23s\n",
      "627:\tlearn: 0.0981180\ttotal: 3.75s\tremaining: 2.22s\n",
      "628:\tlearn: 0.0979750\ttotal: 3.76s\tremaining: 2.22s\n",
      "629:\tlearn: 0.0977941\ttotal: 3.77s\tremaining: 2.21s\n",
      "630:\tlearn: 0.0976480\ttotal: 3.77s\tremaining: 2.21s\n",
      "631:\tlearn: 0.0975442\ttotal: 3.78s\tremaining: 2.2s\n",
      "632:\tlearn: 0.0973592\ttotal: 3.78s\tremaining: 2.19s\n",
      "633:\tlearn: 0.0972443\ttotal: 3.79s\tremaining: 2.19s\n",
      "634:\tlearn: 0.0971208\ttotal: 3.8s\tremaining: 2.18s\n",
      "635:\tlearn: 0.0969294\ttotal: 3.8s\tremaining: 2.18s\n",
      "636:\tlearn: 0.0967833\ttotal: 3.81s\tremaining: 2.17s\n",
      "637:\tlearn: 0.0966454\ttotal: 3.82s\tremaining: 2.17s\n",
      "638:\tlearn: 0.0965015\ttotal: 3.82s\tremaining: 2.16s\n",
      "639:\tlearn: 0.0963456\ttotal: 3.83s\tremaining: 2.15s\n",
      "640:\tlearn: 0.0962494\ttotal: 3.83s\tremaining: 2.15s\n",
      "641:\tlearn: 0.0961245\ttotal: 3.84s\tremaining: 2.14s\n",
      "642:\tlearn: 0.0959670\ttotal: 3.85s\tremaining: 2.13s\n",
      "643:\tlearn: 0.0958098\ttotal: 3.85s\tremaining: 2.13s\n",
      "644:\tlearn: 0.0957065\ttotal: 3.86s\tremaining: 2.12s\n",
      "645:\tlearn: 0.0955432\ttotal: 3.86s\tremaining: 2.12s\n",
      "646:\tlearn: 0.0954035\ttotal: 3.87s\tremaining: 2.11s\n",
      "647:\tlearn: 0.0952402\ttotal: 3.87s\tremaining: 2.1s\n",
      "648:\tlearn: 0.0950914\ttotal: 3.88s\tremaining: 2.1s\n",
      "649:\tlearn: 0.0948989\ttotal: 3.88s\tremaining: 2.09s\n",
      "650:\tlearn: 0.0947902\ttotal: 3.89s\tremaining: 2.08s\n",
      "651:\tlearn: 0.0946791\ttotal: 3.89s\tremaining: 2.08s\n",
      "652:\tlearn: 0.0945684\ttotal: 3.9s\tremaining: 2.07s\n",
      "653:\tlearn: 0.0944082\ttotal: 3.91s\tremaining: 2.07s\n",
      "654:\tlearn: 0.0942497\ttotal: 3.91s\tremaining: 2.06s\n",
      "655:\tlearn: 0.0941245\ttotal: 3.92s\tremaining: 2.05s\n",
      "656:\tlearn: 0.0940297\ttotal: 3.92s\tremaining: 2.05s\n",
      "657:\tlearn: 0.0938550\ttotal: 3.93s\tremaining: 2.04s\n",
      "658:\tlearn: 0.0937346\ttotal: 3.93s\tremaining: 2.04s\n",
      "659:\tlearn: 0.0936032\ttotal: 3.94s\tremaining: 2.03s\n",
      "660:\tlearn: 0.0934872\ttotal: 3.95s\tremaining: 2.02s\n",
      "661:\tlearn: 0.0934094\ttotal: 3.95s\tremaining: 2.02s\n",
      "662:\tlearn: 0.0932675\ttotal: 3.96s\tremaining: 2.01s\n",
      "663:\tlearn: 0.0930772\ttotal: 3.96s\tremaining: 2s\n",
      "664:\tlearn: 0.0929453\ttotal: 3.97s\tremaining: 2s\n",
      "665:\tlearn: 0.0928076\ttotal: 3.97s\tremaining: 1.99s\n",
      "666:\tlearn: 0.0926947\ttotal: 3.98s\tremaining: 1.99s\n",
      "667:\tlearn: 0.0925645\ttotal: 3.98s\tremaining: 1.98s\n",
      "668:\tlearn: 0.0923891\ttotal: 3.99s\tremaining: 1.97s\n",
      "669:\tlearn: 0.0922659\ttotal: 4s\tremaining: 1.97s\n",
      "670:\tlearn: 0.0921537\ttotal: 4s\tremaining: 1.96s\n",
      "671:\tlearn: 0.0920672\ttotal: 4.01s\tremaining: 1.96s\n",
      "672:\tlearn: 0.0919579\ttotal: 4.02s\tremaining: 1.95s\n",
      "673:\tlearn: 0.0918378\ttotal: 4.02s\tremaining: 1.95s\n",
      "674:\tlearn: 0.0917208\ttotal: 4.03s\tremaining: 1.94s\n",
      "675:\tlearn: 0.0916057\ttotal: 4.04s\tremaining: 1.93s\n",
      "676:\tlearn: 0.0915251\ttotal: 4.04s\tremaining: 1.93s\n",
      "677:\tlearn: 0.0914178\ttotal: 4.05s\tremaining: 1.92s\n",
      "678:\tlearn: 0.0913033\ttotal: 4.05s\tremaining: 1.92s\n",
      "679:\tlearn: 0.0911339\ttotal: 4.06s\tremaining: 1.91s\n",
      "680:\tlearn: 0.0910402\ttotal: 4.06s\tremaining: 1.9s\n",
      "681:\tlearn: 0.0909107\ttotal: 4.07s\tremaining: 1.9s\n",
      "682:\tlearn: 0.0907803\ttotal: 4.07s\tremaining: 1.89s\n",
      "683:\tlearn: 0.0906610\ttotal: 4.08s\tremaining: 1.89s\n",
      "684:\tlearn: 0.0905413\ttotal: 4.08s\tremaining: 1.88s\n",
      "685:\tlearn: 0.0904153\ttotal: 4.09s\tremaining: 1.87s\n",
      "686:\tlearn: 0.0902995\ttotal: 4.09s\tremaining: 1.86s\n",
      "687:\tlearn: 0.0901814\ttotal: 4.1s\tremaining: 1.86s\n",
      "688:\tlearn: 0.0900027\ttotal: 4.11s\tremaining: 1.85s\n",
      "689:\tlearn: 0.0898299\ttotal: 4.11s\tremaining: 1.85s\n",
      "690:\tlearn: 0.0897058\ttotal: 4.12s\tremaining: 1.84s\n",
      "691:\tlearn: 0.0895416\ttotal: 4.12s\tremaining: 1.83s\n",
      "692:\tlearn: 0.0894426\ttotal: 4.12s\tremaining: 1.83s\n",
      "693:\tlearn: 0.0892890\ttotal: 4.13s\tremaining: 1.82s\n",
      "694:\tlearn: 0.0891514\ttotal: 4.13s\tremaining: 1.81s\n",
      "695:\tlearn: 0.0890309\ttotal: 4.14s\tremaining: 1.81s\n",
      "696:\tlearn: 0.0889332\ttotal: 4.14s\tremaining: 1.8s\n",
      "697:\tlearn: 0.0888025\ttotal: 4.15s\tremaining: 1.79s\n",
      "698:\tlearn: 0.0886929\ttotal: 4.15s\tremaining: 1.79s\n",
      "699:\tlearn: 0.0885704\ttotal: 4.16s\tremaining: 1.78s\n",
      "700:\tlearn: 0.0884612\ttotal: 4.17s\tremaining: 1.78s\n",
      "701:\tlearn: 0.0883760\ttotal: 4.17s\tremaining: 1.77s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702:\tlearn: 0.0882689\ttotal: 4.18s\tremaining: 1.76s\n",
      "703:\tlearn: 0.0881720\ttotal: 4.18s\tremaining: 1.76s\n",
      "704:\tlearn: 0.0880505\ttotal: 4.19s\tremaining: 1.75s\n",
      "705:\tlearn: 0.0879403\ttotal: 4.2s\tremaining: 1.75s\n",
      "706:\tlearn: 0.0878196\ttotal: 4.21s\tremaining: 1.74s\n",
      "707:\tlearn: 0.0876665\ttotal: 4.21s\tremaining: 1.74s\n",
      "708:\tlearn: 0.0875040\ttotal: 4.22s\tremaining: 1.73s\n",
      "709:\tlearn: 0.0874050\ttotal: 4.22s\tremaining: 1.73s\n",
      "710:\tlearn: 0.0872443\ttotal: 4.23s\tremaining: 1.72s\n",
      "711:\tlearn: 0.0871526\ttotal: 4.24s\tremaining: 1.71s\n",
      "712:\tlearn: 0.0869889\ttotal: 4.24s\tremaining: 1.71s\n",
      "713:\tlearn: 0.0868721\ttotal: 4.25s\tremaining: 1.7s\n",
      "714:\tlearn: 0.0867157\ttotal: 4.25s\tremaining: 1.7s\n",
      "715:\tlearn: 0.0865959\ttotal: 4.26s\tremaining: 1.69s\n",
      "716:\tlearn: 0.0865151\ttotal: 4.26s\tremaining: 1.68s\n",
      "717:\tlearn: 0.0864258\ttotal: 4.27s\tremaining: 1.68s\n",
      "718:\tlearn: 0.0862638\ttotal: 4.28s\tremaining: 1.67s\n",
      "719:\tlearn: 0.0861802\ttotal: 4.28s\tremaining: 1.67s\n",
      "720:\tlearn: 0.0860835\ttotal: 4.29s\tremaining: 1.66s\n",
      "721:\tlearn: 0.0859729\ttotal: 4.3s\tremaining: 1.65s\n",
      "722:\tlearn: 0.0858503\ttotal: 4.3s\tremaining: 1.65s\n",
      "723:\tlearn: 0.0856511\ttotal: 4.31s\tremaining: 1.64s\n",
      "724:\tlearn: 0.0855886\ttotal: 4.32s\tremaining: 1.64s\n",
      "725:\tlearn: 0.0854749\ttotal: 4.33s\tremaining: 1.63s\n",
      "726:\tlearn: 0.0853320\ttotal: 4.33s\tremaining: 1.63s\n",
      "727:\tlearn: 0.0852288\ttotal: 4.34s\tremaining: 1.62s\n",
      "728:\tlearn: 0.0851269\ttotal: 4.35s\tremaining: 1.62s\n",
      "729:\tlearn: 0.0849580\ttotal: 4.36s\tremaining: 1.61s\n",
      "730:\tlearn: 0.0848168\ttotal: 4.38s\tremaining: 1.61s\n",
      "731:\tlearn: 0.0847191\ttotal: 4.39s\tremaining: 1.61s\n",
      "732:\tlearn: 0.0846282\ttotal: 4.4s\tremaining: 1.6s\n",
      "733:\tlearn: 0.0845454\ttotal: 4.41s\tremaining: 1.6s\n",
      "734:\tlearn: 0.0844409\ttotal: 4.42s\tremaining: 1.59s\n",
      "735:\tlearn: 0.0843319\ttotal: 4.42s\tremaining: 1.59s\n",
      "736:\tlearn: 0.0841925\ttotal: 4.43s\tremaining: 1.58s\n",
      "737:\tlearn: 0.0840773\ttotal: 4.44s\tremaining: 1.58s\n",
      "738:\tlearn: 0.0839773\ttotal: 4.45s\tremaining: 1.57s\n",
      "739:\tlearn: 0.0838735\ttotal: 4.46s\tremaining: 1.57s\n",
      "740:\tlearn: 0.0837470\ttotal: 4.47s\tremaining: 1.56s\n",
      "741:\tlearn: 0.0836378\ttotal: 4.48s\tremaining: 1.56s\n",
      "742:\tlearn: 0.0834705\ttotal: 4.49s\tremaining: 1.55s\n",
      "743:\tlearn: 0.0833720\ttotal: 4.5s\tremaining: 1.55s\n",
      "744:\tlearn: 0.0832709\ttotal: 4.51s\tremaining: 1.54s\n",
      "745:\tlearn: 0.0831841\ttotal: 4.51s\tremaining: 1.54s\n",
      "746:\tlearn: 0.0830687\ttotal: 4.52s\tremaining: 1.53s\n",
      "747:\tlearn: 0.0829823\ttotal: 4.53s\tremaining: 1.52s\n",
      "748:\tlearn: 0.0828628\ttotal: 4.53s\tremaining: 1.52s\n",
      "749:\tlearn: 0.0827625\ttotal: 4.54s\tremaining: 1.51s\n",
      "750:\tlearn: 0.0826707\ttotal: 4.54s\tremaining: 1.51s\n",
      "751:\tlearn: 0.0825299\ttotal: 4.55s\tremaining: 1.5s\n",
      "752:\tlearn: 0.0823970\ttotal: 4.55s\tremaining: 1.49s\n",
      "753:\tlearn: 0.0823060\ttotal: 4.56s\tremaining: 1.49s\n",
      "754:\tlearn: 0.0822085\ttotal: 4.57s\tremaining: 1.48s\n",
      "755:\tlearn: 0.0820446\ttotal: 4.57s\tremaining: 1.48s\n",
      "756:\tlearn: 0.0819483\ttotal: 4.58s\tremaining: 1.47s\n",
      "757:\tlearn: 0.0818447\ttotal: 4.59s\tremaining: 1.46s\n",
      "758:\tlearn: 0.0817004\ttotal: 4.59s\tremaining: 1.46s\n",
      "759:\tlearn: 0.0816171\ttotal: 4.6s\tremaining: 1.45s\n",
      "760:\tlearn: 0.0814723\ttotal: 4.61s\tremaining: 1.45s\n",
      "761:\tlearn: 0.0813533\ttotal: 4.61s\tremaining: 1.44s\n",
      "762:\tlearn: 0.0812479\ttotal: 4.62s\tremaining: 1.43s\n",
      "763:\tlearn: 0.0811496\ttotal: 4.62s\tremaining: 1.43s\n",
      "764:\tlearn: 0.0810535\ttotal: 4.63s\tremaining: 1.42s\n",
      "765:\tlearn: 0.0809077\ttotal: 4.63s\tremaining: 1.41s\n",
      "766:\tlearn: 0.0808121\ttotal: 4.64s\tremaining: 1.41s\n",
      "767:\tlearn: 0.0807325\ttotal: 4.64s\tremaining: 1.4s\n",
      "768:\tlearn: 0.0806285\ttotal: 4.65s\tremaining: 1.4s\n",
      "769:\tlearn: 0.0805172\ttotal: 4.65s\tremaining: 1.39s\n",
      "770:\tlearn: 0.0803874\ttotal: 4.66s\tremaining: 1.38s\n",
      "771:\tlearn: 0.0802574\ttotal: 4.66s\tremaining: 1.38s\n",
      "772:\tlearn: 0.0801306\ttotal: 4.67s\tremaining: 1.37s\n",
      "773:\tlearn: 0.0800344\ttotal: 4.67s\tremaining: 1.36s\n",
      "774:\tlearn: 0.0799532\ttotal: 4.68s\tremaining: 1.36s\n",
      "775:\tlearn: 0.0798568\ttotal: 4.68s\tremaining: 1.35s\n",
      "776:\tlearn: 0.0797095\ttotal: 4.69s\tremaining: 1.34s\n",
      "777:\tlearn: 0.0796042\ttotal: 4.69s\tremaining: 1.34s\n",
      "778:\tlearn: 0.0794971\ttotal: 4.7s\tremaining: 1.33s\n",
      "779:\tlearn: 0.0793680\ttotal: 4.7s\tremaining: 1.33s\n",
      "780:\tlearn: 0.0792354\ttotal: 4.71s\tremaining: 1.32s\n",
      "781:\tlearn: 0.0790860\ttotal: 4.71s\tremaining: 1.31s\n",
      "782:\tlearn: 0.0789577\ttotal: 4.72s\tremaining: 1.31s\n",
      "783:\tlearn: 0.0788255\ttotal: 4.72s\tremaining: 1.3s\n",
      "784:\tlearn: 0.0787381\ttotal: 4.73s\tremaining: 1.29s\n",
      "785:\tlearn: 0.0786329\ttotal: 4.74s\tremaining: 1.29s\n",
      "786:\tlearn: 0.0785460\ttotal: 4.74s\tremaining: 1.28s\n",
      "787:\tlearn: 0.0784447\ttotal: 4.75s\tremaining: 1.28s\n",
      "788:\tlearn: 0.0783529\ttotal: 4.75s\tremaining: 1.27s\n",
      "789:\tlearn: 0.0782283\ttotal: 4.76s\tremaining: 1.26s\n",
      "790:\tlearn: 0.0781283\ttotal: 4.77s\tremaining: 1.26s\n",
      "791:\tlearn: 0.0780423\ttotal: 4.77s\tremaining: 1.25s\n",
      "792:\tlearn: 0.0779474\ttotal: 4.78s\tremaining: 1.25s\n",
      "793:\tlearn: 0.0778204\ttotal: 4.78s\tremaining: 1.24s\n",
      "794:\tlearn: 0.0777209\ttotal: 4.79s\tremaining: 1.24s\n",
      "795:\tlearn: 0.0776538\ttotal: 4.8s\tremaining: 1.23s\n",
      "796:\tlearn: 0.0775711\ttotal: 4.8s\tremaining: 1.22s\n",
      "797:\tlearn: 0.0774986\ttotal: 4.81s\tremaining: 1.22s\n",
      "798:\tlearn: 0.0774096\ttotal: 4.81s\tremaining: 1.21s\n",
      "799:\tlearn: 0.0773183\ttotal: 4.82s\tremaining: 1.2s\n",
      "800:\tlearn: 0.0772187\ttotal: 4.82s\tremaining: 1.2s\n",
      "801:\tlearn: 0.0771157\ttotal: 4.83s\tremaining: 1.19s\n",
      "802:\tlearn: 0.0769889\ttotal: 4.83s\tremaining: 1.19s\n",
      "803:\tlearn: 0.0768951\ttotal: 4.84s\tremaining: 1.18s\n",
      "804:\tlearn: 0.0767566\ttotal: 4.84s\tremaining: 1.17s\n",
      "805:\tlearn: 0.0766488\ttotal: 4.85s\tremaining: 1.17s\n",
      "806:\tlearn: 0.0765550\ttotal: 4.85s\tremaining: 1.16s\n",
      "807:\tlearn: 0.0764729\ttotal: 4.86s\tremaining: 1.15s\n",
      "808:\tlearn: 0.0763650\ttotal: 4.87s\tremaining: 1.15s\n",
      "809:\tlearn: 0.0762806\ttotal: 4.87s\tremaining: 1.14s\n",
      "810:\tlearn: 0.0761932\ttotal: 4.88s\tremaining: 1.14s\n",
      "811:\tlearn: 0.0761014\ttotal: 4.88s\tremaining: 1.13s\n",
      "812:\tlearn: 0.0760235\ttotal: 4.89s\tremaining: 1.12s\n",
      "813:\tlearn: 0.0759257\ttotal: 4.89s\tremaining: 1.12s\n",
      "814:\tlearn: 0.0758300\ttotal: 4.9s\tremaining: 1.11s\n",
      "815:\tlearn: 0.0757313\ttotal: 4.9s\tremaining: 1.1s\n",
      "816:\tlearn: 0.0756509\ttotal: 4.91s\tremaining: 1.1s\n",
      "817:\tlearn: 0.0755713\ttotal: 4.92s\tremaining: 1.09s\n",
      "818:\tlearn: 0.0754923\ttotal: 4.92s\tremaining: 1.09s\n",
      "819:\tlearn: 0.0754236\ttotal: 4.93s\tremaining: 1.08s\n",
      "820:\tlearn: 0.0753353\ttotal: 4.93s\tremaining: 1.07s\n",
      "821:\tlearn: 0.0752601\ttotal: 4.94s\tremaining: 1.07s\n",
      "822:\tlearn: 0.0751052\ttotal: 4.95s\tremaining: 1.06s\n",
      "823:\tlearn: 0.0749788\ttotal: 4.95s\tremaining: 1.06s\n",
      "824:\tlearn: 0.0748985\ttotal: 4.96s\tremaining: 1.05s\n",
      "825:\tlearn: 0.0748094\ttotal: 4.96s\tremaining: 1.04s\n",
      "826:\tlearn: 0.0747345\ttotal: 4.97s\tremaining: 1.04s\n",
      "827:\tlearn: 0.0746348\ttotal: 4.97s\tremaining: 1.03s\n",
      "828:\tlearn: 0.0745426\ttotal: 4.98s\tremaining: 1.03s\n",
      "829:\tlearn: 0.0744381\ttotal: 4.99s\tremaining: 1.02s\n",
      "830:\tlearn: 0.0743544\ttotal: 4.99s\tremaining: 1.01s\n",
      "831:\tlearn: 0.0742447\ttotal: 5s\tremaining: 1.01s\n",
      "832:\tlearn: 0.0741141\ttotal: 5s\tremaining: 1s\n",
      "833:\tlearn: 0.0740208\ttotal: 5.01s\tremaining: 997ms\n",
      "834:\tlearn: 0.0739191\ttotal: 5.01s\tremaining: 991ms\n",
      "835:\tlearn: 0.0738503\ttotal: 5.02s\tremaining: 984ms\n",
      "836:\tlearn: 0.0737804\ttotal: 5.02s\tremaining: 978ms\n",
      "837:\tlearn: 0.0736943\ttotal: 5.03s\tremaining: 972ms\n",
      "838:\tlearn: 0.0735507\ttotal: 5.03s\tremaining: 966ms\n",
      "839:\tlearn: 0.0734460\ttotal: 5.04s\tremaining: 960ms\n",
      "840:\tlearn: 0.0733506\ttotal: 5.04s\tremaining: 954ms\n",
      "841:\tlearn: 0.0732737\ttotal: 5.05s\tremaining: 948ms\n",
      "842:\tlearn: 0.0731739\ttotal: 5.06s\tremaining: 942ms\n",
      "843:\tlearn: 0.0731090\ttotal: 5.06s\tremaining: 936ms\n",
      "844:\tlearn: 0.0730370\ttotal: 5.07s\tremaining: 929ms\n",
      "845:\tlearn: 0.0729586\ttotal: 5.07s\tremaining: 923ms\n",
      "846:\tlearn: 0.0728290\ttotal: 5.08s\tremaining: 917ms\n",
      "847:\tlearn: 0.0727353\ttotal: 5.08s\tremaining: 911ms\n",
      "848:\tlearn: 0.0726420\ttotal: 5.09s\tremaining: 905ms\n",
      "849:\tlearn: 0.0725706\ttotal: 5.09s\tremaining: 899ms\n",
      "850:\tlearn: 0.0724345\ttotal: 5.1s\tremaining: 893ms\n",
      "851:\tlearn: 0.0722910\ttotal: 5.1s\tremaining: 887ms\n",
      "852:\tlearn: 0.0722095\ttotal: 5.11s\tremaining: 881ms\n",
      "853:\tlearn: 0.0721206\ttotal: 5.12s\tremaining: 875ms\n",
      "854:\tlearn: 0.0720204\ttotal: 5.12s\tremaining: 869ms\n",
      "855:\tlearn: 0.0719325\ttotal: 5.13s\tremaining: 863ms\n",
      "856:\tlearn: 0.0718421\ttotal: 5.13s\tremaining: 857ms\n",
      "857:\tlearn: 0.0717642\ttotal: 5.14s\tremaining: 851ms\n",
      "858:\tlearn: 0.0716622\ttotal: 5.15s\tremaining: 845ms\n",
      "859:\tlearn: 0.0715646\ttotal: 5.15s\tremaining: 839ms\n",
      "860:\tlearn: 0.0714487\ttotal: 5.16s\tremaining: 833ms\n",
      "861:\tlearn: 0.0713294\ttotal: 5.16s\tremaining: 827ms\n",
      "862:\tlearn: 0.0712040\ttotal: 5.17s\tremaining: 820ms\n",
      "863:\tlearn: 0.0711132\ttotal: 5.17s\tremaining: 814ms\n",
      "864:\tlearn: 0.0710453\ttotal: 5.18s\tremaining: 808ms\n",
      "865:\tlearn: 0.0709753\ttotal: 5.18s\tremaining: 802ms\n",
      "866:\tlearn: 0.0708601\ttotal: 5.19s\tremaining: 796ms\n",
      "867:\tlearn: 0.0707808\ttotal: 5.2s\tremaining: 790ms\n",
      "868:\tlearn: 0.0706940\ttotal: 5.2s\tremaining: 784ms\n",
      "869:\tlearn: 0.0705863\ttotal: 5.21s\tremaining: 778ms\n",
      "870:\tlearn: 0.0705087\ttotal: 5.21s\tremaining: 772ms\n",
      "871:\tlearn: 0.0704234\ttotal: 5.22s\tremaining: 766ms\n",
      "872:\tlearn: 0.0702894\ttotal: 5.22s\tremaining: 760ms\n",
      "873:\tlearn: 0.0701842\ttotal: 5.23s\tremaining: 754ms\n",
      "874:\tlearn: 0.0701057\ttotal: 5.24s\tremaining: 748ms\n",
      "875:\tlearn: 0.0700240\ttotal: 5.24s\tremaining: 742ms\n",
      "876:\tlearn: 0.0699375\ttotal: 5.25s\tremaining: 736ms\n",
      "877:\tlearn: 0.0698614\ttotal: 5.25s\tremaining: 730ms\n",
      "878:\tlearn: 0.0697694\ttotal: 5.26s\tremaining: 724ms\n",
      "879:\tlearn: 0.0696973\ttotal: 5.27s\tremaining: 718ms\n",
      "880:\tlearn: 0.0696138\ttotal: 5.27s\tremaining: 712ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881:\tlearn: 0.0695311\ttotal: 5.28s\tremaining: 706ms\n",
      "882:\tlearn: 0.0694355\ttotal: 5.28s\tremaining: 700ms\n",
      "883:\tlearn: 0.0693583\ttotal: 5.29s\tremaining: 694ms\n",
      "884:\tlearn: 0.0692417\ttotal: 5.3s\tremaining: 688ms\n",
      "885:\tlearn: 0.0691651\ttotal: 5.3s\tremaining: 682ms\n",
      "886:\tlearn: 0.0690839\ttotal: 5.31s\tremaining: 677ms\n",
      "887:\tlearn: 0.0689646\ttotal: 5.32s\tremaining: 671ms\n",
      "888:\tlearn: 0.0688151\ttotal: 5.33s\tremaining: 665ms\n",
      "889:\tlearn: 0.0687215\ttotal: 5.33s\tremaining: 659ms\n",
      "890:\tlearn: 0.0686593\ttotal: 5.34s\tremaining: 653ms\n",
      "891:\tlearn: 0.0685687\ttotal: 5.34s\tremaining: 647ms\n",
      "892:\tlearn: 0.0684679\ttotal: 5.35s\tremaining: 641ms\n",
      "893:\tlearn: 0.0684019\ttotal: 5.36s\tremaining: 635ms\n",
      "894:\tlearn: 0.0683460\ttotal: 5.36s\tremaining: 629ms\n",
      "895:\tlearn: 0.0682298\ttotal: 5.37s\tremaining: 623ms\n",
      "896:\tlearn: 0.0681613\ttotal: 5.37s\tremaining: 617ms\n",
      "897:\tlearn: 0.0680513\ttotal: 5.38s\tremaining: 611ms\n",
      "898:\tlearn: 0.0679715\ttotal: 5.38s\tremaining: 605ms\n",
      "899:\tlearn: 0.0678871\ttotal: 5.39s\tremaining: 599ms\n",
      "900:\tlearn: 0.0678274\ttotal: 5.4s\tremaining: 593ms\n",
      "901:\tlearn: 0.0677429\ttotal: 5.4s\tremaining: 587ms\n",
      "902:\tlearn: 0.0676597\ttotal: 5.41s\tremaining: 581ms\n",
      "903:\tlearn: 0.0675957\ttotal: 5.41s\tremaining: 575ms\n",
      "904:\tlearn: 0.0674753\ttotal: 5.42s\tremaining: 569ms\n",
      "905:\tlearn: 0.0673753\ttotal: 5.43s\tremaining: 563ms\n",
      "906:\tlearn: 0.0672675\ttotal: 5.43s\tremaining: 557ms\n",
      "907:\tlearn: 0.0671602\ttotal: 5.44s\tremaining: 551ms\n",
      "908:\tlearn: 0.0670833\ttotal: 5.44s\tremaining: 545ms\n",
      "909:\tlearn: 0.0669898\ttotal: 5.45s\tremaining: 539ms\n",
      "910:\tlearn: 0.0669118\ttotal: 5.45s\tremaining: 533ms\n",
      "911:\tlearn: 0.0668067\ttotal: 5.46s\tremaining: 527ms\n",
      "912:\tlearn: 0.0667229\ttotal: 5.46s\tremaining: 521ms\n",
      "913:\tlearn: 0.0666526\ttotal: 5.47s\tremaining: 515ms\n",
      "914:\tlearn: 0.0665686\ttotal: 5.48s\tremaining: 509ms\n",
      "915:\tlearn: 0.0664798\ttotal: 5.49s\tremaining: 503ms\n",
      "916:\tlearn: 0.0664280\ttotal: 5.49s\tremaining: 497ms\n",
      "917:\tlearn: 0.0663589\ttotal: 5.5s\tremaining: 491ms\n",
      "918:\tlearn: 0.0662960\ttotal: 5.5s\tremaining: 485ms\n",
      "919:\tlearn: 0.0661578\ttotal: 5.51s\tremaining: 479ms\n",
      "920:\tlearn: 0.0660616\ttotal: 5.51s\tremaining: 473ms\n",
      "921:\tlearn: 0.0659712\ttotal: 5.52s\tremaining: 467ms\n",
      "922:\tlearn: 0.0659019\ttotal: 5.53s\tremaining: 461ms\n",
      "923:\tlearn: 0.0658313\ttotal: 5.53s\tremaining: 455ms\n",
      "924:\tlearn: 0.0657526\ttotal: 5.54s\tremaining: 449ms\n",
      "925:\tlearn: 0.0656797\ttotal: 5.54s\tremaining: 443ms\n",
      "926:\tlearn: 0.0655678\ttotal: 5.55s\tremaining: 437ms\n",
      "927:\tlearn: 0.0655039\ttotal: 5.55s\tremaining: 431ms\n",
      "928:\tlearn: 0.0654346\ttotal: 5.56s\tremaining: 425ms\n",
      "929:\tlearn: 0.0653520\ttotal: 5.56s\tremaining: 419ms\n",
      "930:\tlearn: 0.0652510\ttotal: 5.57s\tremaining: 413ms\n",
      "931:\tlearn: 0.0651507\ttotal: 5.57s\tremaining: 407ms\n",
      "932:\tlearn: 0.0650873\ttotal: 5.58s\tremaining: 401ms\n",
      "933:\tlearn: 0.0649768\ttotal: 5.58s\tremaining: 395ms\n",
      "934:\tlearn: 0.0648859\ttotal: 5.59s\tremaining: 389ms\n",
      "935:\tlearn: 0.0647929\ttotal: 5.59s\tremaining: 383ms\n",
      "936:\tlearn: 0.0646788\ttotal: 5.6s\tremaining: 377ms\n",
      "937:\tlearn: 0.0646036\ttotal: 5.61s\tremaining: 370ms\n",
      "938:\tlearn: 0.0645402\ttotal: 5.61s\tremaining: 364ms\n",
      "939:\tlearn: 0.0644322\ttotal: 5.62s\tremaining: 358ms\n",
      "940:\tlearn: 0.0643627\ttotal: 5.62s\tremaining: 352ms\n",
      "941:\tlearn: 0.0642588\ttotal: 5.63s\tremaining: 346ms\n",
      "942:\tlearn: 0.0641511\ttotal: 5.63s\tremaining: 340ms\n",
      "943:\tlearn: 0.0640377\ttotal: 5.63s\tremaining: 334ms\n",
      "944:\tlearn: 0.0639895\ttotal: 5.64s\tremaining: 328ms\n",
      "945:\tlearn: 0.0639070\ttotal: 5.65s\tremaining: 322ms\n",
      "946:\tlearn: 0.0637878\ttotal: 5.66s\tremaining: 317ms\n",
      "947:\tlearn: 0.0637177\ttotal: 5.66s\tremaining: 311ms\n",
      "948:\tlearn: 0.0636215\ttotal: 5.67s\tremaining: 305ms\n",
      "949:\tlearn: 0.0635565\ttotal: 5.68s\tremaining: 299ms\n",
      "950:\tlearn: 0.0634864\ttotal: 5.68s\tremaining: 293ms\n",
      "951:\tlearn: 0.0634367\ttotal: 5.69s\tremaining: 287ms\n",
      "952:\tlearn: 0.0633733\ttotal: 5.69s\tremaining: 281ms\n",
      "953:\tlearn: 0.0633125\ttotal: 5.7s\tremaining: 275ms\n",
      "954:\tlearn: 0.0632497\ttotal: 5.7s\tremaining: 269ms\n",
      "955:\tlearn: 0.0631226\ttotal: 5.71s\tremaining: 263ms\n",
      "956:\tlearn: 0.0630446\ttotal: 5.71s\tremaining: 257ms\n",
      "957:\tlearn: 0.0629986\ttotal: 5.72s\tremaining: 251ms\n",
      "958:\tlearn: 0.0629194\ttotal: 5.72s\tremaining: 245ms\n",
      "959:\tlearn: 0.0628687\ttotal: 5.73s\tremaining: 239ms\n",
      "960:\tlearn: 0.0628107\ttotal: 5.73s\tremaining: 233ms\n",
      "961:\tlearn: 0.0627538\ttotal: 5.74s\tremaining: 227ms\n",
      "962:\tlearn: 0.0626341\ttotal: 5.74s\tremaining: 221ms\n",
      "963:\tlearn: 0.0625766\ttotal: 5.75s\tremaining: 215ms\n",
      "964:\tlearn: 0.0625110\ttotal: 5.75s\tremaining: 209ms\n",
      "965:\tlearn: 0.0624560\ttotal: 5.76s\tremaining: 203ms\n",
      "966:\tlearn: 0.0623990\ttotal: 5.76s\tremaining: 197ms\n",
      "967:\tlearn: 0.0623213\ttotal: 5.77s\tremaining: 191ms\n",
      "968:\tlearn: 0.0622646\ttotal: 5.77s\tremaining: 185ms\n",
      "969:\tlearn: 0.0622050\ttotal: 5.78s\tremaining: 179ms\n",
      "970:\tlearn: 0.0621202\ttotal: 5.78s\tremaining: 173ms\n",
      "971:\tlearn: 0.0620544\ttotal: 5.79s\tremaining: 167ms\n",
      "972:\tlearn: 0.0620002\ttotal: 5.79s\tremaining: 161ms\n",
      "973:\tlearn: 0.0619151\ttotal: 5.8s\tremaining: 155ms\n",
      "974:\tlearn: 0.0618116\ttotal: 5.8s\tremaining: 149ms\n",
      "975:\tlearn: 0.0617434\ttotal: 5.81s\tremaining: 143ms\n",
      "976:\tlearn: 0.0616721\ttotal: 5.81s\tremaining: 137ms\n",
      "977:\tlearn: 0.0616165\ttotal: 5.82s\tremaining: 131ms\n",
      "978:\tlearn: 0.0615702\ttotal: 5.83s\tremaining: 125ms\n",
      "979:\tlearn: 0.0614974\ttotal: 5.83s\tremaining: 119ms\n",
      "980:\tlearn: 0.0614247\ttotal: 5.84s\tremaining: 113ms\n",
      "981:\tlearn: 0.0613627\ttotal: 5.85s\tremaining: 107ms\n",
      "982:\tlearn: 0.0612841\ttotal: 5.85s\tremaining: 101ms\n",
      "983:\tlearn: 0.0612068\ttotal: 5.86s\tremaining: 95.3ms\n",
      "984:\tlearn: 0.0611386\ttotal: 5.87s\tremaining: 89.3ms\n",
      "985:\tlearn: 0.0610648\ttotal: 5.87s\tremaining: 83.4ms\n",
      "986:\tlearn: 0.0609729\ttotal: 5.88s\tremaining: 77.4ms\n",
      "987:\tlearn: 0.0608825\ttotal: 5.88s\tremaining: 71.4ms\n",
      "988:\tlearn: 0.0607959\ttotal: 5.89s\tremaining: 65.5ms\n",
      "989:\tlearn: 0.0607306\ttotal: 5.89s\tremaining: 59.5ms\n",
      "990:\tlearn: 0.0606535\ttotal: 5.9s\tremaining: 53.6ms\n",
      "991:\tlearn: 0.0605609\ttotal: 5.9s\tremaining: 47.6ms\n",
      "992:\tlearn: 0.0604837\ttotal: 5.91s\tremaining: 41.6ms\n",
      "993:\tlearn: 0.0603997\ttotal: 5.91s\tremaining: 35.7ms\n",
      "994:\tlearn: 0.0603195\ttotal: 5.92s\tremaining: 29.7ms\n",
      "995:\tlearn: 0.0602311\ttotal: 5.92s\tremaining: 23.8ms\n",
      "996:\tlearn: 0.0601571\ttotal: 5.93s\tremaining: 17.8ms\n",
      "997:\tlearn: 0.0600909\ttotal: 5.93s\tremaining: 11.9ms\n",
      "998:\tlearn: 0.0600281\ttotal: 5.94s\tremaining: 5.94ms\n",
      "999:\tlearn: 0.0599450\ttotal: 5.94s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cat.fit(X_train, y_train)\n",
    "train_preds = cat.predict(X_train)\n",
    "test_preds = cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Gini = 0.9976553341148886\n",
      "Test Gini = 0.8905432855728366\n"
     ]
    }
   ],
   "source": [
    "print('Train Gini = {}'.format(2 * roc_auc_score(y_train, train_preds) - 1))\n",
    "print('Test Gini = {}'.format(2 * roc_auc_score(y_test, test_preds) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = Seniority_committee(N=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making hyperplane number 1\n",
      "X_train.shape[0] = 7000\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -4.475228710275801\n",
      "Time taken for optimization: 12.969997882843018\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -2.053475325832409\n",
      "Time taken for optimization: 10.468002080917358\n",
      "X_1.shape[0] = 438\n",
      "X_0.shape[0] = 498\n",
      "\n",
      "Making hyperplane number 2\n",
      "X_train.shape[0] = 6502\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -1.6046620104040894\n",
      "Time taken for optimization: 9.124000072479248\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.7387080207667914\n",
      "Time taken for optimization: 6.244002819061279\n",
      "X_1.shape[0] = 425\n",
      "X_0.shape[0] = 138\n",
      "\n",
      "Making hyperplane number 3\n",
      "X_train.shape[0] = 6077\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.6831807590565888\n",
      "Time taken for optimization: 9.522999286651611\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -5.592711936314734\n",
      "Time taken for optimization: 8.310999631881714\n",
      "X_1.shape[0] = 134\n",
      "X_0.shape[0] = 276\n",
      "\n",
      "Making hyperplane number 4\n",
      "X_train.shape[0] = 5801\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.7543579709917939\n",
      "Time taken for optimization: 9.240004301071167\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.13526433481909805\n",
      "Time taken for optimization: 6.8349974155426025\n",
      "X_1.shape[0] = 77\n",
      "X_0.shape[0] = 15\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -4.549161460159913\n",
      "Time taken for optimization: 11.304997444152832\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.21402807466487125\n",
      "Time taken for optimization: 7.080003261566162\n",
      "X_1.shape[0] = 512\n",
      "X_0.shape[0] = 77\n",
      "\n",
      "Making hyperplane number 5\n",
      "X_train.shape[0] = 5289\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.4157535371505597\n",
      "Time taken for optimization: 6.8869993686676025\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.11812027774890135\n",
      "Time taken for optimization: 6.269001245498657\n",
      "X_1.shape[0] = 61\n",
      "X_0.shape[0] = 14\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.3998522953446698\n",
      "Time taken for optimization: 10.010998010635376\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -3.2615991098282686\n",
      "Time taken for optimization: 8.611003637313843\n",
      "X_1.shape[0] = 77\n",
      "X_0.shape[0] = 525\n",
      "\n",
      "Making hyperplane number 6\n",
      "X_train.shape[0] = 4764\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.29138081875401434\n",
      "Time taken for optimization: 6.7909979820251465\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.403593553955716\n",
      "Time taken for optimization: 6.101003170013428\n",
      "X_1.shape[0] = 54\n",
      "X_0.shape[0] = 49\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.31698495735338744\n",
      "Time taken for optimization: 10.06299901008606\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.2551035243807568\n",
      "Time taken for optimization: 7.0109992027282715\n",
      "X_1.shape[0] = 71\n",
      "X_0.shape[0] = 50\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.5841995110585064\n",
      "Time taken for optimization: 9.421000719070435\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.6257336306806225\n",
      "Time taken for optimization: 7.632997989654541\n",
      "X_1.shape[0] = 88\n",
      "X_0.shape[0] = 79\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -7.02756821806384\n",
      "Time taken for optimization: 11.834999799728394\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -171.50874957181495\n",
      "Time taken for optimization: 8.256001710891724\n",
      "X_1.shape[0] = 177\n",
      "X_0.shape[0] = 259\n",
      "\n",
      "Making hyperplane number 7\n",
      "X_train.shape[0] = 4505\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.3732151495014322\n",
      "Time taken for optimization: 8.240999460220337\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.17924394232418822\n",
      "Time taken for optimization: 6.457000494003296\n",
      "X_1.shape[0] = 40\n",
      "X_0.shape[0] = 31\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.4932114909498956\n",
      "Time taken for optimization: 9.338997840881348\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.3677604291166739\n",
      "Time taken for optimization: 6.019005298614502\n",
      "X_1.shape[0] = 99\n",
      "X_0.shape[0] = 51\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.655390537222107\n",
      "Time taken for optimization: 9.633996486663818\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.12461709581815633\n",
      "Time taken for optimization: 7.174999475479126\n",
      "X_1.shape[0] = 76\n",
      "X_0.shape[0] = 33\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -111.90731700332536\n",
      "Time taken for optimization: 10.297003030776978\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.6416169998003307\n",
      "Time taken for optimization: 9.341998100280762\n",
      "X_1.shape[0] = 186\n",
      "X_0.shape[0] = 37\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -178.07058914221568\n",
      "Time taken for optimization: 12.222998857498169\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -262.33522332066923\n",
      "Time taken for optimization: 10.868000745773315\n",
      "X_1.shape[0] = 264\n",
      "X_0.shape[0] = 661\n",
      "\n",
      "Making hyperplane number 8\n",
      "X_train.shape[0] = 3844\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.1993824486764283\n",
      "Time taken for optimization: 6.143001079559326\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.258274978767431\n",
      "Time taken for optimization: 4.658996820449829\n",
      "X_1.shape[0] = 36\n",
      "X_0.shape[0] = 15\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum of the loss function: -0.4001062188594795\n",
      "Time taken for optimization: 7.190000772476196\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.1806141109237554\n",
      "Time taken for optimization: 5.255000114440918\n",
      "X_1.shape[0] = 44\n",
      "X_0.shape[0] = 34\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -1.3571895932907754\n",
      "Time taken for optimization: 9.632001638412476\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.3179918819337001\n",
      "Time taken for optimization: 6.561000823974609\n",
      "X_1.shape[0] = 117\n",
      "X_0.shape[0] = 60\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -125.44865997504198\n",
      "Time taken for optimization: 9.889997959136963\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.4799028087413789\n",
      "Time taken for optimization: 7.1910014152526855\n",
      "X_1.shape[0] = 150\n",
      "X_0.shape[0] = 41\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -198.82502148885644\n",
      "Time taken for optimization: 10.99000072479248\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.706640433830729\n",
      "Time taken for optimization: 6.927002668380737\n",
      "X_1.shape[0] = 297\n",
      "X_0.shape[0] = 224\n",
      "\n",
      "Making hyperplane number 9\n",
      "X_train.shape[0] = 3547\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.2554090471849052\n",
      "Time taken for optimization: 6.15200138092041\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.29895841556335995\n",
      "Time taken for optimization: 4.4699976444244385\n",
      "X_1.shape[0] = 33\n",
      "X_0.shape[0] = 26\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.28385991448965514\n",
      "Time taken for optimization: 6.821002721786499\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.1554956983195707\n",
      "Time taken for optimization: 4.618999481201172\n",
      "X_1.shape[0] = 29\n",
      "X_0.shape[0] = 15\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.6369489108695776\n",
      "Time taken for optimization: 7.283998489379883\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.7440264552296874\n",
      "Time taken for optimization: 10.811001777648926\n",
      "X_1.shape[0] = 87\n",
      "X_0.shape[0] = 64\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -124.81978779087385\n",
      "Time taken for optimization: 10.492998361587524\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.43856273003011487\n",
      "Time taken for optimization: 8.513001441955566\n",
      "X_1.shape[0] = 153\n",
      "X_0.shape[0] = 75\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -139.68600501350988\n",
      "Time taken for optimization: 11.99499797821045\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -34.6887521412878\n",
      "Time taken for optimization: 11.649002075195312\n",
      "X_1.shape[0] = 251\n",
      "X_0.shape[0] = 80\n",
      "\n",
      "Making hyperplane number 10\n",
      "X_train.shape[0] = 3296\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.10073994382843884\n",
      "Time taken for optimization: 7.962003469467163\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.09974075713094956\n",
      "Time taken for optimization: 6.81100058555603\n",
      "X_1.shape[0] = 15\n",
      "X_0.shape[0] = 14\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.22723111057071682\n",
      "Time taken for optimization: 8.816001176834106\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.4955953866240638\n",
      "Time taken for optimization: 7.506998062133789\n",
      "X_1.shape[0] = 35\n",
      "X_0.shape[0] = 71\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.7567518026030073\n",
      "Time taken for optimization: 10.318003416061401\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.43152863441135847\n",
      "Time taken for optimization: 10.173996210098267\n",
      "X_1.shape[0] = 165\n",
      "X_0.shape[0] = 31\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -34.663009583529366\n",
      "Time taken for optimization: 10.557001829147339\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.9552113362159936\n",
      "Time taken for optimization: 12.170000076293945\n",
      "X_1.shape[0] = 54\n",
      "X_0.shape[0] = 81\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -87.2384592086438\n",
      "Time taken for optimization: 11.456999063491821\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -35.80453017669053\n",
      "Time taken for optimization: 12.450998306274414\n",
      "X_1.shape[0] = 109\n",
      "X_0.shape[0] = 150\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 2\n",
      "L = 4\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -168.3591065563503\n",
      "Time taken for optimization: 15.597002267837524\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -331.55550724467594\n",
      "Time taken for optimization: 16.24099826812744\n",
      "X_1.shape[0] = 325\n",
      "X_0.shape[0] = 1115\n",
      "\n",
      "Making hyperplane number 11\n",
      "X_train.shape[0] = 2181\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.20479296387805018\n",
      "Time taken for optimization: 6.729997873306274\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.17095360022288508\n",
      "Time taken for optimization: 4.983000755310059\n",
      "X_1.shape[0] = 25\n",
      "X_0.shape[0] = 15\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.440212398975201\n",
      "Time taken for optimization: 6.901005268096924\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.18547604528708955\n",
      "Time taken for optimization: 4.742997407913208\n",
      "X_1.shape[0] = 45\n",
      "X_0.shape[0] = 23\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.46485825641171474\n",
      "Time taken for optimization: 6.75300145149231\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.24967005286006208\n",
      "Time taken for optimization: 6.061000347137451\n",
      "X_1.shape[0] = 59\n",
      "X_0.shape[0] = 26\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First approximation is obtained\n",
      "The minimum of the loss function: -1.6080510941290616\n",
      "Time taken for optimization: 6.89300012588501\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.44769998598705923\n",
      "Time taken for optimization: 6.219996690750122\n",
      "X_1.shape[0] = 122\n",
      "X_0.shape[0] = 43\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -114.3087572392438\n",
      "Time taken for optimization: 8.245999336242676\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -35.98519123162917\n",
      "Time taken for optimization: 8.896003007888794\n",
      "X_1.shape[0] = 160\n",
      "X_0.shape[0] = 59\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 2\n",
      "L = 4\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -166.30868490495783\n",
      "Time taken for optimization: 9.17099905014038\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -80.44045874282486\n",
      "Time taken for optimization: 8.129002094268799\n",
      "X_1.shape[0] = 267\n",
      "X_0.shape[0] = 222\n",
      "\n",
      "Making hyperplane number 12\n",
      "X_train.shape[0] = 1914\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.3041024402081844\n",
      "Time taken for optimization: 3.7490031719207764\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.45287812686344786\n",
      "Time taken for optimization: 4.033998727798462\n",
      "X_1.shape[0] = 24\n",
      "X_0.shape[0] = 41\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.17818364777515727\n",
      "Time taken for optimization: 3.6649985313415527\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.17114909277909718\n",
      "Time taken for optimization: 3.4670004844665527\n",
      "X_1.shape[0] = 16\n",
      "X_0.shape[0] = 15\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.43972038157863946\n",
      "Time taken for optimization: 4.849998950958252\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.7948002523814235\n",
      "Time taken for optimization: 5.277001857757568\n",
      "X_1.shape[0] = 39\n",
      "X_0.shape[0] = 36\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -18.716348569356306\n",
      "Time taken for optimization: 5.6309967041015625\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.4079881101111805\n",
      "Time taken for optimization: 5.339000701904297\n",
      "X_1.shape[0] = 23\n",
      "X_0.shape[0] = 34\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -64.32241423000985\n",
      "Time taken for optimization: 6.7880003452301025\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -60.71918238297962\n",
      "Time taken for optimization: 7.262002229690552\n",
      "X_1.shape[0] = 87\n",
      "X_0.shape[0] = 95\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 2\n",
      "L = 4\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -83.26878063704022\n",
      "Time taken for optimization: 6.916999578475952\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -99.79952401075855\n",
      "Time taken for optimization: 8.013998746871948\n",
      "X_1.shape[0] = 106\n",
      "X_0.shape[0] = 179\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 1\n",
      "L = 2\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -92.9390594281176\n",
      "Time taken for optimization: 9.711997747421265\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -329.465933603009\n",
      "Time taken for optimization: 14.151000261306763\n",
      "X_1.shape[0] = 162\n",
      "X_0.shape[0] = 1129\n",
      "\n",
      "Making hyperplane number 13\n",
      "X_train.shape[0] = 785\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.4372508194062681\n",
      "Time taken for optimization: 2.214035987854004\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.3196510090221416\n",
      "Time taken for optimization: 2.1731984615325928\n",
      "X_1.shape[0] = 38\n",
      "X_0.shape[0] = 24\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.5324591778791886\n",
      "Time taken for optimization: 2.6780009269714355\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.15218733456387945\n",
      "Time taken for optimization: 2.054676055908203\n",
      "X_1.shape[0] = 46\n",
      "X_0.shape[0] = 17\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.6454605913989627\n",
      "Time taken for optimization: 3.3969924449920654\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.3674434563064797\n",
      "Time taken for optimization: 2.5469980239868164\n",
      "X_1.shape[0] = 48\n",
      "X_0.shape[0] = 26\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -49.674858233092166\n",
      "Time taken for optimization: 4.045002222061157\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.35184152272883223\n",
      "Time taken for optimization: 3.4509971141815186\n",
      "X_1.shape[0] = 63\n",
      "X_0.shape[0] = 30\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -58.502524216463\n",
      "Time taken for optimization: 4.826948404312134\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -18.0\n",
      "Time taken for optimization: 4.291030406951904\n",
      "X_1.shape[0] = 74\n",
      "X_0.shape[0] = 18\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 2\n",
      "L = 4\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -72.04824896874855\n",
      "Time taken for optimization: 4.522937297821045\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -38.761008696702596\n",
      "Time taken for optimization: 4.624999523162842\n",
      "X_1.shape[0] = 108\n",
      "X_0.shape[0] = 44\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 1\n",
      "L = 2\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -86.81201216259748\n",
      "Time taken for optimization: 5.698030710220337\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -61.76336833077614\n",
      "Time taken for optimization: 5.301044702529907\n",
      "X_1.shape[0] = 135\n",
      "X_0.shape[0] = 218\n",
      "\n",
      "Making hyperplane number 14\n",
      "X_train.shape[0] = 567\n",
      "k = 7\n",
      "L = 128\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.501573067895594\n",
      "Time taken for optimization: 2.229952335357666\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.054368160148590174\n",
      "Time taken for optimization: 1.5650300979614258\n",
      "X_1.shape[0] = 32\n",
      "X_0.shape[0] = 6\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 6\n",
      "L = 64\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.30275931397709227\n",
      "Time taken for optimization: 2.3950343132019043\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.2853065231360034\n",
      "Time taken for optimization: 1.995964765548706\n",
      "X_1.shape[0] = 24\n",
      "X_0.shape[0] = 15\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 5\n",
      "L = 32\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.29823810544260865\n",
      "Time taken for optimization: 2.578974723815918\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.09391642991852531\n",
      "Time taken for optimization: 1.8240046501159668\n",
      "X_1.shape[0] = 29\n",
      "X_0.shape[0] = 10\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 4\n",
      "L = 16\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -40.13191586486988\n",
      "Time taken for optimization: 2.9439942836761475\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -0.38753391664965475\n",
      "Time taken for optimization: 2.4850149154663086\n",
      "X_1.shape[0] = 54\n",
      "X_0.shape[0] = 16\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 3\n",
      "L = 8\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -64.06156739219821\n",
      "Time taken for optimization: 4.221035957336426\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -13.497669886017984\n",
      "Time taken for optimization: 2.869962692260742\n",
      "X_1.shape[0] = 88\n",
      "X_0.shape[0] = 29\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 2\n",
      "L = 4\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -72.54034140617233\n",
      "Time taken for optimization: 5.546037673950195\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -27.467156167100658\n",
      "Time taken for optimization: 3.0229713916778564\n",
      "X_1.shape[0] = 100\n",
      "X_0.shape[0] = 32\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 1\n",
      "L = 2\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -85.29685975633727\n",
      "Time taken for optimization: 5.646009922027588\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -33.07013068477468\n",
      "Time taken for optimization: 4.1490254402160645\n",
      "X_1.shape[0] = 128\n",
      "X_0.shape[0] = 68\n",
      "Cutted data shape is not enough\n",
      "\n",
      "k = 0\n",
      "L = 1\n",
      "Optimizing hyperplane for class 1\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -105.67462942336098\n",
      "Time taken for optimization: 3.204986095428467\n",
      "Optimizing hyperplane for class 0\n",
      "Optimization is started\n",
      "First approximation is obtained\n",
      "The minimum of the loss function: -65.09662901550718\n",
      "Time taken for optimization: 5.571964502334595\n",
      "X_1.shape[0] = 365\n",
      "X_0.shape[0] = 290\n",
      "\n",
      "Time taken to fit the model: 843.6088690757751\n"
     ]
    }
   ],
   "source": [
    "sc.fit(X_train, y_train, optim_method='TNC', maxiter=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0,\n",
       "  array([ 0.02632503,  0.00947681,  0.02221152,  0.00546112, -0.03185218,\n",
       "         -0.01688269, -0.00128826, -0.01516088,  0.01930865,  0.00258797,\n",
       "          0.02175838, -0.00548834, -0.03907981]),\n",
       "  0.010040160642570281,\n",
       "  0.39280221470316823),\n",
       " 2: (1,\n",
       "  array([-0.00064097, -0.03423908, -0.00771906,  0.00411564,  0.0310691 ,\n",
       "          0.01224259,  0.01019396,  0.01003542, -0.01299394,  0.00241912,\n",
       "         -0.01007858, -0.01674524, -0.01342609]),\n",
       "  0.9882352941176471,\n",
       "  0.3511601118973178),\n",
       " 3: (0,\n",
       "  array([ 0.04891442,  0.11570378,  0.08105102,  0.09823202,  0.01049999,\n",
       "         -0.01858941, -0.04516226, -0.14609608, -0.03482756,  0.04701864,\n",
       "          0.02849533,  0.08884397, -0.26327153]),\n",
       "  0.010869565217391304,\n",
       "  0.36735045681779005),\n",
       " 4: (1,\n",
       "  array([-0.0203427 ,  0.00064881, -0.02292468, -0.03376307,  0.01170043,\n",
       "          0.00179792,  0.00860155, -0.00158963, -0.03162534, -0.04033961,\n",
       "         -0.02391733, -0.02513087,  0.05806062]),\n",
       "  0.98828125,\n",
       "  0.3072414445074683),\n",
       " 5: (0,\n",
       "  array([ 0.03092462,  0.00879638,  0.03715619,  0.04072396, -0.05323873,\n",
       "         -0.0108766 , -0.02621677, -0.00839854,  0.01010034, -0.00289143,\n",
       "          0.02333656,  0.02443186, -0.0612228 ]),\n",
       "  0.009523809523809525,\n",
       "  0.34005037783375314),\n",
       " 6: (0,\n",
       "  array([ 12.0694866 ,  19.64540151,  18.37288346,   9.16575165,\n",
       "         -23.5158744 ,   0.63260933,  -7.54053586,  -7.34155579,\n",
       "          10.66337867,  13.28743259,   6.53867   ,  -3.63706617,\n",
       "         -37.18059612]),\n",
       "  0.023166023166023165,\n",
       "  0.35826859045504994),\n",
       " 7: (0,\n",
       "  array([ 4.54564008,  5.02623529,  3.13121713,  4.40746481, -8.23590851,\n",
       "         -4.09673597, -1.31198501, -1.55496156,  2.94822847,  5.08280336,\n",
       "          0.3944036 ,  3.41104048, -9.11351931]),\n",
       "  0.07110438729198185,\n",
       "  0.40764828303850154),\n",
       " 8: (1,\n",
       "  array([-10.9403992 ,  -3.75536963,   0.16207678,  -0.94582004,\n",
       "           3.52274042,   1.31672467,   1.09453903,   1.34432849,\n",
       "           0.29397721,  -3.22848171,  -4.45964348,  -4.43164815,\n",
       "           4.51096723]),\n",
       "  0.9461279461279462,\n",
       "  0.36255990978291514),\n",
       " 9: (1,\n",
       "  array([ 0.25457575, -3.55087833,  0.08452776, -9.34670537,  2.37713646,\n",
       "          0.74606735,  0.9911455 ,  0.2749462 , -1.89581712, -0.87080103,\n",
       "         -2.25706097,  1.25817063,  1.31240948]),\n",
       "  0.9322709163346613,\n",
       "  0.3191747572815534),\n",
       " 10: (0,\n",
       "  array([  4.24732447,   3.39359788,   5.73717918,   4.10954188,\n",
       "          -2.6704113 ,  -2.08519907,  -1.09778797,  -2.38470757,\n",
       "           4.89583082,   1.94751148,   4.30965625,   2.23317012,\n",
       "         -11.69345214]),\n",
       "  0.15067264573991032,\n",
       "  0.4053186611646034),\n",
       " 11: (1,\n",
       "  array([ -1.73026609,   0.55509204, -17.05218948,  -3.02617508,\n",
       "           1.7658023 ,   1.46177678,  -0.15113759,  -0.18863227,\n",
       "          -6.51767073,  -8.43355502,   1.80389273,  -6.98324888,\n",
       "          10.74811735]),\n",
       "  0.9063670411985019,\n",
       "  0.335423197492163),\n",
       " 12: (0,\n",
       "  array([ 2.9862874 ,  1.69121666,  4.03333622,  7.61384841, -6.74909758,\n",
       "         -1.35518075, -2.28667399, -4.40186991,  1.24695892,  5.51814834,\n",
       "          3.15310738,  5.4430183 , -6.75339244]),\n",
       "  0.2462356067316209,\n",
       "  0.4636942675159236),\n",
       " 13: (0,\n",
       "  array([ 3.31852885,  0.32462541,  3.32078893, -1.76650561, -2.35766351,\n",
       "         -2.21971906,  0.40535428, -2.06794824,  5.84592287,  3.10520475,\n",
       "          2.62400469, -6.7840621 , -4.05795393]),\n",
       "  0.26605504587155965,\n",
       "  0.5396825396825397),\n",
       " 14: (1,\n",
       "  array([-3.44088019,  2.33784531, -0.22198768, -1.2493015 ,  1.18840115,\n",
       "          0.50782929,  0.43696729,  2.36450026, -3.81590941, -3.55616668,\n",
       "         -4.71955964,  1.66285391,  3.19325991]),\n",
       "  0.6328767123287671,\n",
       "  0.3712871287128713)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.weights_hp # optim_weights = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(optim_weights).to_pickle('weights_without_last_list.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_1 = Seniority_committee(N=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_1.weights_hp = sc.weights_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict the targets: 5.581000566482544\n"
     ]
    }
   ],
   "source": [
    "train_proba = sc_1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict the targets: 2.4260308742523193\n"
     ]
    }
   ],
   "source": [
    "test_proba = sc_1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Gini = 0.8493163678990727\n"
     ]
    }
   ],
   "source": [
    "print('Train Gini = {}'.format(2 * roc_auc_score(y_train, train_proba) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Gini = 0.8326556582748381\n"
     ]
    }
   ],
   "source": [
    "print('Test Gini = {}'.format(2 * roc_auc_score(y_test, test_proba) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict the targets: 5.325000762939453\n",
      "Time taken to predict the targets: 2.3600258827209473\n",
      "Train F1 = 0.8186484174508126\n",
      "Test F1 = 0.8044806517311609\n"
     ]
    }
   ],
   "source": [
    "train_preds = sc_1.predict(X_train)\n",
    "test_preds = sc_1.predict(X_test)\n",
    "print('Train F1 = {}'.format(f1_score(y_train, train_preds)))\n",
    "print('Test F1 = {}'.format(f1_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.8788571428571429\n",
      "Test accuracy = 0.872\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy = {}'.format(accuracy_score(y_train, train_preds)))\n",
    "print('Test accuracy = {}'.format(accuracy_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seniority_committee:\n",
    "    \"\"\"\n",
    "        ML Algo based on the seniority committee method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        \"\"\"\n",
    "            :param N: число наблюдений, находящихся выше гиперплоскости\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.L = -1\n",
    "        self.N = N\n",
    "        self.weights_hp = dict() # здесь будут записаны оптимальные веса гиперплоскостей в виде: \n",
    "                                 # {'num_hyperplane': (voted_class, optim_weights, probability)}\n",
    "        self.optim_params = dict() # здесь будут записаны параметры оптимизации гиперплоскостей в виде:\n",
    "                   # {'cycle_range': int, 'disp': bool, 'adaptive': bool, 'maxiter': int or None, 'xatol': float or None}\n",
    "                   # значение параметров дано в описании метода make_hyperplane\n",
    "        \n",
    "    def expand(self, X):\n",
    "        \"\"\"\n",
    "            Concatenates the feature matrix with the column of ones\n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :returns: исходная матрица признаков со столбцом единиц (добавили bias)\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        ones_col = np.ones(len(X_new))\n",
    "        ones_col.shape = (len(X_new), 1)\n",
    "        X_new = np.hstack((X_new, ones_col))\n",
    "        return X_new\n",
    "    \n",
    "    \n",
    "    def probability(self, X, w):\n",
    "        \"\"\"\n",
    "            Принимает на вход матрицу фичей и вектор весов\n",
    "            Возвращает предсказание вероятность того, что y = 1 при фиксированных x, P(y=1|x)\n",
    "\n",
    "            :param X: матрица признаков \n",
    "            :param w: вектор весов\n",
    "            :returns: вероятность того, что y = 1 при фиксированных x, P(y=1|x) ## вектор вероятностей = ReLU1(X.T*w)\n",
    "        \"\"\"\n",
    "        \n",
    "        linear = np.dot(X, w)\n",
    "        linear[linear < 0] = 0\n",
    "        linear[linear > 1] = 1\n",
    "        \n",
    "        return linear\n",
    "    \n",
    "    \n",
    "    def compute_loss(self, X, y, w):\n",
    "        \"\"\"\n",
    "            Принимает на вход матрицу весов, вектор ответов, вектор весов и параметр L, \n",
    "            влияющий на долю класса 0 в отсекающей гиперплоскости.\n",
    "            Выдаёт на выход значение функции потерь\n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :param w: вектор целевой переменной\n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь\n",
    "        \"\"\"\n",
    "        \n",
    "        p1 = self.probability(X, w)\n",
    "        loss = np.sum((self.L - (self.L + 1) * y) * p1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def compute_train_loss_class_0(self, w):\n",
    "        \"\"\"\n",
    "            Function that we want to minimize, the committee member votes for class 1\n",
    "            \n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь на обучающей выборке, когда член коммитета голосует за класс 0\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        return self.compute_loss(self.X_train, 1 - self.y_train, w)\n",
    "    \n",
    "    \n",
    "    def compute_train_loss_class_1(self, w):\n",
    "        \"\"\"\n",
    "            Function that we want to minimize, the committee member votes for class 1\n",
    "            \n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь на обучающей выборке, когда член коммитета голосует за класс 1\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        return self.compute_loss(self.X_train, self.y_train, w)\n",
    "    \n",
    "    \n",
    "    def make_hyperplane(self, class_num, X_train, optim_method, c=0.1, cycle_range=100, disp=False, \\\n",
    "                        adaptive=True, maxiter=None, xatol=None, verbose=0):\n",
    "        \"\"\"\n",
    "            Function that makes one of three hyperplanes\n",
    "            \n",
    "            :param class_num: класс, за который голосует данный член комитета: [0, 1]\n",
    "            :param X_train: матрица признаков обучающей выборки\n",
    "            :param optim_method: метод оптимизации: ['Nelder-Mead', 'differential_evolution', 'BFGS', 'CG', 'SLSQP', \\\n",
    "                                                    'COBYLA', 'TNC']\n",
    "            :param с: вспомогательный коэффициент для выбора начального приближения\n",
    "            :param cycle_range: количество итераций минимизации функции потерь\n",
    "            Параметры оптимизации с помощью алгоритма Нелдера-Мида:\n",
    "                :param disp: bool: печать сообщения о сходимости\n",
    "                :param adaptive: bool: адаптация параметров алгоритма для размерности задачи (полезно при больших размерностях)\n",
    "                :param maxiter: максимально допустимое количество итераций при оптимизации\n",
    "                :param xatol: абсолютная ошибка на оптимальных точках между итерациями, приемлемая для сходимости\n",
    "            :param verbose: подробный вывод описания обучения: [0, 1, 2]:\n",
    "                0 - не печатать ничего\n",
    "                1 - печатать общее время обучения\n",
    "                2 - подробный вывод информации о процессе обучения\n",
    "            :returns: значение функции потерь на тестовой выборке\n",
    "        \"\"\"\n",
    "\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Using make_hyperplane method before fitting')\n",
    "        if class_num not in [0, 1]:\n",
    "            raise Exception('Only binary classification is available, class_num should be 0 or 1')\n",
    "        if optim_method not in ['Nelder-Mead', 'differential_evolution', 'BFGS', 'CG', 'SLSQP', \\\n",
    "                                                    'COBYLA', 'TNC']:\n",
    "            raise Exception(\"Unavailable optimization method, only ['Nelder-Mead', 'differential_evolution', 'BFGS', 'CG', 'SLSQP', 'COBYLA', 'TNC'] are available\")\n",
    "        \n",
    "        optim_result = []\n",
    "        optim_result_more_precise = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if verbose == 2:\n",
    "            print('Optimization is started')\n",
    "        \n",
    "        if optim_method == 'Nelder-Mead':\n",
    "            \n",
    "            for i in range(cycle_range):\n",
    "\n",
    "                start_w = np.array((np.random.rand(X_train.shape[1]) - 0.5) * c)\n",
    "\n",
    "                if class_num == 1:\n",
    "\n",
    "                        res = minimize(self.compute_train_loss_class_1, x0=start_w, method='Nelder-Mead', \\\n",
    "                                       options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "\n",
    "                elif class_num == 0:\n",
    "\n",
    "                        res = minimize(self.compute_train_loss_class_0, x0=start_w, method='Nelder-Mead', \\\n",
    "                                       options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "\n",
    "                optim_result.append([res.fun, res.x])\n",
    "\n",
    "\n",
    "            if optim_result == []:\n",
    "                raise Exception('We\\'ve not get any satisfying first approximation')\n",
    "\n",
    "            optim_result.sort(key=lambda x: x[0])\n",
    "            optim_result = [x[1] for x in optim_result][:int(0.1 * cycle_range)]\n",
    "            \n",
    "            if verbose == 2:\n",
    "                print('First approximation is obtained')\n",
    "\n",
    "            for start_w_new in optim_result:\n",
    "\n",
    "                if class_num == 1:\n",
    "                    res = minimize(self.compute_train_loss_class_1, x0=start_w_new, method='Nelder-Mead', \\\n",
    "                             options={'disp': False, 'adaptive':True, 'xatol':1})\n",
    "                elif class_num == 0:\n",
    "                    res = minimize(self.compute_train_loss_class_0, x0=start_w_new, method='Nelder-Mead', \\\n",
    "                             options={'disp': False, 'adaptive':True, 'xatol':1})\n",
    "\n",
    "                for k in range(2):\n",
    "                    if class_num == 1:\n",
    "                        res = minimize(self.compute_train_loss_class_1, x0=res.x, method='Nelder-Mead', \\\n",
    "                                 options={'disp': False, 'adaptive':True})\n",
    "                    elif class_num == 0:\n",
    "                        res = minimize(self.compute_train_loss_class_0, x0=res.x, method='Nelder-Mead', \\\n",
    "                                 options={'disp': False, 'adaptive':True})\n",
    "\n",
    "                optim_result_more_precise += [[res.fun, res.x]]\n",
    "                \n",
    "            optim_result_more_precise = pd.DataFrame(optim_result_more_precise)\n",
    "            optim_result_more_precise = optim_result_more_precise.sort_values(0).head(1)\n",
    "            hyperplane_coefficients = optim_result_more_precise[1].values[0]\n",
    "            min_loss_func = optim_result_more_precise[0].values[0]\n",
    "        \n",
    "        elif optim_method == 'differential_evolution':\n",
    "            \n",
    "            bounds = []\n",
    "            for j in range(X_train.shape[1]):\n",
    "                bounds.append((-10, 10))\n",
    "                \n",
    "            if class_num == 1:\n",
    "                res = differential_evolution(self.compute_train_loss_class_1, bounds=bounds)\n",
    "            \n",
    "            if class_num == 0:\n",
    "                res = differential_evolution(self.compute_train_loss_class_0, bounds=bounds)\n",
    "            \n",
    "            hyperplane_coefficients = res.x\n",
    "            min_loss_func = res.fun\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            for i in range(cycle_range):\n",
    "\n",
    "                start_w = np.array((np.random.rand(X_train.shape[1]) - 0.5) * c)\n",
    "\n",
    "                if class_num == 1:\n",
    "\n",
    "                        res = minimize(self.compute_train_loss_class_1, x0=start_w, method=optim_method)\n",
    "\n",
    "                elif class_num == 0:\n",
    "\n",
    "                        res = minimize(self.compute_train_loss_class_0, x0=start_w, method=optim_method)\n",
    "\n",
    "                optim_result.append([res.fun, res.x])\n",
    "\n",
    "\n",
    "            if optim_result == []:\n",
    "                raise Exception('We\\'ve not get any satisfying first approximation')\n",
    "\n",
    "            optim_result.sort(key=lambda x: x[0])\n",
    "            optim_result = [x[1] for x in optim_result][:int(0.1 * cycle_range)]\n",
    "            \n",
    "            if verbose == 2:\n",
    "                print('First approximation is obtained')\n",
    "\n",
    "            for start_w_new in optim_result:\n",
    "\n",
    "                if class_num == 1:\n",
    "                    res = minimize(self.compute_train_loss_class_1, x0=start_w_new, method=optim_method)\n",
    "                elif class_num == 0:\n",
    "                    res = minimize(self.compute_train_loss_class_0, x0=start_w_new, method=optim_method)\n",
    "\n",
    "                for k in range(2):\n",
    "                    if class_num == 1:\n",
    "                        res = minimize(self.compute_train_loss_class_1, x0=res.x, method=optim_method)\n",
    "                    elif class_num == 0:\n",
    "                        res = minimize(self.compute_train_loss_class_0, x0=res.x, method=optim_method)\n",
    "\n",
    "                optim_result_more_precise += [[res.fun, res.x]]\n",
    "                \n",
    "            optim_result_more_precise = pd.DataFrame(optim_result_more_precise)\n",
    "            optim_result_more_precise = optim_result_more_precise.sort_values(0).head(1)\n",
    "            hyperplane_coefficients = optim_result_more_precise[1].values[0]\n",
    "            min_loss_func = optim_result_more_precise[0].values[0]\n",
    "        \n",
    "        if verbose == 2:\n",
    "            print('The minimum of the loss function: {0}'.format(min_loss_func))\n",
    "        if verbose == 2:\n",
    "            print('Time taken for optimization: {0}'.format(time.time() - start_time))\n",
    "\n",
    "        return hyperplane_coefficients\n",
    "        \n",
    "    \n",
    "    def cutter(self, X, w):\n",
    "        \"\"\"\n",
    "            Function that makes binary targets for rational numbers\n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :param w: вектор оптимальных весов\n",
    "            :returns: бинаризованные предсказания целевой переменной\n",
    "        \"\"\"\n",
    "        \n",
    "        linear = np.dot(X, w)\n",
    "        linear[linear < 0] = 0\n",
    "        \n",
    "        return np.sign(linear)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, optim_method='Nelder-Mead', cycle_range=100, disp=False, adaptive=True, maxiter=10, xatol=0.3, \\\n",
    "           verbose=0):\n",
    "        \"\"\"\n",
    "            Fits the algorithm on the train sample \n",
    "            \n",
    "            :param X: матрица признаков, обучающая выборка\n",
    "            :param y: вектор истинных значений целевой переменной обучающей выборки\n",
    "            :param optim_method: метод оптимизации: ['Nelder-Mead', 'differential_evolution', 'BFGS', 'CG', 'SLSQP', \\\n",
    "                                                    'COBYLA', 'TNC']\n",
    "            Параметры оптимизации с помощью алгоритма Нелдера-Мида:\n",
    "                :param disp: bool: печать сообщения о сходимости\n",
    "                :param adaptive: bool: адаптация параметров алгоритма для размерности задачи (полезно при больших размерностях)\n",
    "                :param maxiter: максимально допустимое количество итераций при оптимизации\n",
    "                :param xatol: абсолютная ошибка на оптимальных точках между итерациями, приемлемая для сходимости\n",
    "            :param verbose: подробный вывод описания обучения: [0, 1, 2]:\n",
    "                0 - не печатать ничего\n",
    "                1 - печатать общее время обучения\n",
    "                2 - подробный вывод информации о процессе обучения\n",
    "            :returns: -, но на выходе обученная моделька\n",
    "        \"\"\"\n",
    "        \n",
    "        start_of_fit_time = time.time()\n",
    "        \n",
    "        X_new = self.expand(X)\n",
    "        \n",
    "        self.X_train = X_new\n",
    "        self.y_train = y\n",
    "        self.optim_params = {'cycle_range': cycle_range, 'disp': disp, 'adaptive': adaptive, \\\n",
    "                             'maxiter': maxiter, 'xatol': xatol}\n",
    "        \n",
    "        hp_num = 1\n",
    "        \n",
    "        while self.X_train.shape[0] > 2 * self.N:\n",
    "            \n",
    "            if verbose == 2:\n",
    "                print('Making hyperplane number {}'.format(hp_num))\n",
    "                print('X_train.shape[0] = {}'.format(self.X_train.shape[0]))\n",
    "            \n",
    "            k = 7\n",
    "            \n",
    "            while True:\n",
    "                \n",
    "                if verbose == 2:\n",
    "                    print('k = {}'.format(k))\n",
    "                \n",
    "                self.L = 2 ** k\n",
    "                \n",
    "                if verbose == 2:\n",
    "                    print('L = {}'.format(self.L))\n",
    "                \n",
    "                if verbose == 2:\n",
    "                    print('Optimizing hyperplane for class 1')\n",
    "                \n",
    "                hp_weights_class_1 = self.make_hyperplane(class_num=1, X_train=self.X_train, \\\n",
    "                                                     optim_method=optim_method, \\\n",
    "                                                     c=0.1, cycle_range=self.optim_params['cycle_range'], \\\n",
    "                                                     disp=self.optim_params['disp'], \\\n",
    "                                                     adaptive=self.optim_params['adaptive'], \\\n",
    "                                                     maxiter=self.optim_params['maxiter'], \\\n",
    "                                                     xatol=self.optim_params['xatol'], \\\n",
    "                                                     verbose=verbose)\n",
    "                \n",
    "                if verbose == 2:\n",
    "                    print('Optimizing hyperplane for class 0')\n",
    "                \n",
    "                hp_weights_class_0 = self.make_hyperplane(class_num=0, X_train=self.X_train, \\\n",
    "                                                     optim_method=optim_method, \\\n",
    "                                                     c=0.1, cycle_range=self.optim_params['cycle_range'], \\\n",
    "                                                     disp=self.optim_params['disp'], \\\n",
    "                                                     adaptive=self.optim_params['adaptive'], \\\n",
    "                                                     maxiter=self.optim_params['maxiter'], \\\n",
    "                                                     xatol=self.optim_params['xatol'], \\\n",
    "                                                     verbose=verbose)\n",
    "                \n",
    "                cut_1 = self.cutter(self.X_train, hp_weights_class_1)\n",
    "                cut_0 = self.cutter(self.X_train, hp_weights_class_0)\n",
    "                X_1 = self.X_train[cut_1 == 1]\n",
    "                y_1 = self.y_train[cut_1 == 1]\n",
    "                y_1_rest = self.y_train[cut_1 == 0] # оставшиеся после отсечения сэмплы\n",
    "                X_0 = self.X_train[cut_0 == 1]\n",
    "                y_0 = self.y_train[cut_0 == 1]\n",
    "                y_0_rest = self.y_train[cut_0 == 0] # оставшиеся после отсечения сэмплы\n",
    "                \n",
    "                if verbose == 2:\n",
    "                    print('X_1.shape[0] = {}'.format(X_1.shape[0]))\n",
    "                    print('X_0.shape[0] = {}'.format(X_0.shape[0]))\n",
    "                \n",
    "                if X_1.shape[0] < self.N and X_0.shape[0] < self.N:\n",
    "                    \n",
    "                    if verbose == 2:\n",
    "                        print('Cutted data shape is not enough\\n')\n",
    "                    k -= 1\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    if X_1.shape[0] >= X_0.shape[0]:\n",
    "                        \n",
    "                        proba = y_1.sum() / len(y_1)\n",
    "                        proba_rest = y_1_rest.sum() / len(y_1_rest)\n",
    "                        self.weights_hp[hp_num] = (1, hp_weights_class_1, proba, proba_rest)\n",
    "                        \n",
    "                        self.X_train = self.X_train[cut_1 == 0]\n",
    "                        self.y_train = self.y_train[cut_1 == 0]\n",
    "                        \n",
    "                    elif X_1.shape[0] < X_0.shape[0]:\n",
    "                        \n",
    "                        proba = y_0.sum() / len(y_0)\n",
    "                        proba_rest = y_0_rest.sum() / len(y_0_rest)\n",
    "                        self.weights_hp[hp_num] = (0, hp_weights_class_0, proba, proba_rest)\n",
    "                        \n",
    "                        self.X_train = self.X_train[cut_0 == 0]\n",
    "                        self.y_train = self.y_train[cut_0 == 0]\n",
    "                        \n",
    "                    hp_num += 1\n",
    "                    if verbose == 2:\n",
    "                        print()\n",
    "                    break\n",
    "                    \n",
    "        end_of_fit_time = time.time()\n",
    "        \n",
    "        if verbose == 2 or verbose == 1:\n",
    "            print('Time taken to fit the model: {0}'.format(end_of_fit_time - start_of_fit_time))\n",
    "                \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "            Makes predict_proba for the sample\n",
    "            \n",
    "            :param X: матрица признаков, обучающая выборка\n",
    "            :returns: предсказания вероятностей отнесения к классу 1\n",
    "        \"\"\"\n",
    "        \n",
    "        start_of_predict_time = time.time()\n",
    "        \n",
    "        X_new = self.expand(X)\n",
    "        \n",
    "        test_ = X_new.copy()\n",
    "        \n",
    "        if self.weights_hp == {}:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        predictions = pd.DataFrame({'proba': np.zeros(X.shape[0]), 'is_scored': False})\n",
    "        \n",
    "        for hp_num in self.weights_hp.keys():\n",
    "            \n",
    "            class_num, weights, proba, proba_rest = self.weights_hp[hp_num]\n",
    "            \n",
    "            cut = self.cutter(test_, weights)\n",
    "            \n",
    "            X_ = test_[cut == 1]\n",
    "            test_ = test_[cut == 0]\n",
    "            \n",
    "            k = 0\n",
    "            for i in range(predictions.shape[0]):\n",
    "                \n",
    "                if predictions.loc[i, 'is_scored'] == False:\n",
    "                    if cut[k] == True:\n",
    "                        predictions.loc[i, 'proba'] = proba\n",
    "                        predictions.loc[i, 'is_scored'] = True\n",
    "                    k += 1\n",
    "            if hp_num == list(self.weights_hp.keys())[-1]:\n",
    "                for i in range(predictions.shape[0]):\n",
    "                    if predictions.loc[i, 'is_scored'] == False:\n",
    "                        predictions.loc[i, 'proba'] = proba_rest\n",
    "                        predictions.loc[i, 'is_scored'] = True\n",
    "                        \n",
    "        end_of_predict_time = time.time()\n",
    "        print('Time taken to predict the targets: {0}'.format(end_of_predict_time - start_of_predict_time))\n",
    "        \n",
    "        return predictions['proba'].values\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Makes predict_proba for the sample\n",
    "            \n",
    "            :param X: матрица признаков, обучающая выборка\n",
    "            :returns: предсказания классов\n",
    "        \"\"\"\n",
    "        \n",
    "        proba = self.predict_proba(X)\n",
    "        return np.array([round(x) for x in proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
