{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Устойчивост эл_сети.xlsx\",engine='openpyxl',sheet_name='Data_for_UCI_named')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  0.023892  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120 -0.025803    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984 -0.031810    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  0.037789  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  0.045263  unstable  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'unstable': 0, 'stable': 1}\n",
    "df.stabf = df.stabf.map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab  stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347      0  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957      1  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471      0  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871      0  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stab', 'stabf'], axis=1).values\n",
    "y = df.stabf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    X[:,i]=(X[:,i]-X[:,i].min())/(X[:,i].max()-X[:,i].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.array([0, 1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seniority_committee:\n",
    "    \"\"\"\n",
    "        ML Algo based on the seniority committee method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        \"\"\"\n",
    "            :param N: число наблюдений, находящихся выше гиперплоскости\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.L = -1\n",
    "        self.N = N\n",
    "        self.weights_hp = []\n",
    "        \n",
    "    def probability(X, w):\n",
    "        \"\"\"\n",
    "            Принимает на вход матрицу фичей и вектор весов\n",
    "            Возвращает предсказание вероятность того, что y = 1 при фиксированных x, P(y=1|x)\n",
    "\n",
    "            :param X: матрица признаков ## расширенная матрица фичей [n_samples,6] (expanded)\n",
    "            :param w: вектор весов ## [6]\n",
    "            :returns: вероятность того, что y = 1 при фиксированных x, P(y=1|x) ## вектор вероятностей = ReLU1(X.T*w)\n",
    "        \"\"\"\n",
    "        \n",
    "        linear = np.dot(X, w)\n",
    "        linear[linear < 0] = 0\n",
    "        linear[linear > 1] = 1\n",
    "        \n",
    "        return linear\n",
    "    \n",
    "    def compute_loss(X, y, w):\n",
    "        \"\"\"\n",
    "            Принимает на вход матрицу весов, вектор ответов, вектор весов и параметр L, \n",
    "            влияющий на долю класса 0 в отсекающей гиперплоскости.\n",
    "            Выдаёт на выход значение функции потерь ## расчитанное по формуле выше.\n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :param w: вектор целевой переменной\n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь\n",
    "        \"\"\"\n",
    "        \n",
    "        p1 = probability(X, w)\n",
    "        loss = np.sum((self.L - (self.L + 1) * y) * p1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def compute_train_loss_class_0(w):\n",
    "        \"\"\"\n",
    "            Function that we want to minimize, the committee member votes for class 1\n",
    "            \n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь на обучающей выборке\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        return compute_loss(self.X_train, 1 - self.y_train, w)\n",
    "    \n",
    "    def compute_train_loss_class_1(w):\n",
    "        \"\"\"\n",
    "            Function that we want to minimize, the committee member votes for class 1\n",
    "            \n",
    "            :param w: вектор весов\n",
    "            :returns: значение функции потерь на обучающей выборке\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Model is not fitted')\n",
    "        \n",
    "        return compute_loss(self.X_train, self.y_train, w)\n",
    "    \n",
    "    def make_hyperplane(class_num, X_train, number_of_hyperplane, c=0.1, cycle_range=100, disp=False, \\\n",
    "                        adaptive=True, maxiter=None, xatol=None):\n",
    "        \"\"\"\n",
    "            Function that makes one of three hyperplanes\n",
    "            \n",
    "            :param class_num: класс, за который голосует данный член комитета: [0, 1]\n",
    "            :param X_train: матрица признаков обучающей выборки\n",
    "            :param number_of_hyperplane: порядковый номер гиперплоскости: [1, 2, 3]\n",
    "            :param с: вспомогательный коэффициент для выбора начального приближения\n",
    "            :param cycle_range: количество итераций минимизации функции потерь\n",
    "            Параметры оптимизации с помощью алгоритма Нелдера-Мида:\n",
    "                :param disp: bool: печать сообщения о сходимости\n",
    "                :param adaptive: bool: адаптация параметров алгоритма для размерности задачи (полезно при больших размерностях)\n",
    "                :param maxiter: максимально допустимое количество итераций при оптимизации\n",
    "                :param xatol: абсолютная ошибка на оптимальных точках между итерациями, приемлемая для сходимости\n",
    "            :returns: значение функции потерь на тестовой выборке\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise Exception('Using make_hyperplane method before fitting')\n",
    "        if number_of_hyperplane not in [1, 2, 3]:\n",
    "            raise Exception('You can only make hyperplane number 1, 2 or 3')\n",
    "        if class_num not in [0, 1]:\n",
    "            raise Exception('Only binary classification is available, class_num should be 0 or 1')\n",
    "        \n",
    "        optim_result = []\n",
    "        start_time = time.time()\n",
    "        if number_of_hyperplane == 1:\n",
    "\n",
    "            for i in range(cycle_range):\n",
    "                start_w = np.array([(np.random.rand(X_train.shape[1]) - 0.5) * c])\n",
    "                if class_num == 1:\n",
    "                    res = minimize(compute_train_loss_class_1, x0=start_w, method='Nelder-Mead', \\\n",
    "                                   options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "                elif class_num == 0:\n",
    "                    res = minimize(compute_train_loss_class_0, x0=start_w, method='Nelder-Mead', \\\n",
    "                                   options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "                optim_result += [[i, res.fun, res.x]]\n",
    "\n",
    "            optim_result = pd.DataFrame(optim_result)\n",
    "            optim_result = optim_result.sort_values(1).head(1)\n",
    "            hyperplane_coefficients = optim_result[2].values[0]\n",
    "            print('Time taken for optimization: {0}'.format(time.time() - start_time))\n",
    "            print('The best result was on the step {0}'.format(optim_result[0].values[0]))\n",
    "            print('The minimum of the loss function: {0}'.format(optim_result[1].values[0]))\n",
    "\n",
    "#             self.weights_hp_1 = hyperplane_coefficients\n",
    "            return hyperplane_coefficients\n",
    "\n",
    "        elif number_of_hyperplane == 2:\n",
    "\n",
    "            for i in range(cycle_range):\n",
    "                start_w = np.array((np.random.rand(X_train.shape[1]) - 0.5) * c)\n",
    "                if class_num == 1:\n",
    "                    res = minimize(compute_train_loss_class_1, x0=start_w, method='Nelder-Mead', \\\n",
    "                                   options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "                elif class_num == 0:\n",
    "                    res = minimize(compute_train_loss_class_0, x0=start_w, method='Nelder-Mead', \\\n",
    "                                   options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "                optim_result += [[i, res.fun, res.x]] # , start_loss, start_w\n",
    "\n",
    "            optim_result = pd.DataFrame(optim_result)\n",
    "            optim_result = optim_result.sort_values(1).head(1)\n",
    "            hyperplane_coefficients = optim_result[2].values[0]\n",
    "            print('Time taken for optimization: {0}'.format(time.time() - start_time))\n",
    "            print('The best result was on the step {0}'.format(optim_result[0].values[0]))\n",
    "            print('The minimum of the loss function: {0}'.format(optim_result[1].values[0]))\n",
    "\n",
    "#             self.weights_hp_2 = hyperplane_coefficients\n",
    "            return hyperplane_coefficients\n",
    "\n",
    "        elif number_of_hyperplane == 3:\n",
    "\n",
    "            optim_result_new = []\n",
    "\n",
    "            for i in range(cycle_range):\n",
    "                start_w = np.array((np.random.rand(X_test.shape[1])-0.5)*c)\n",
    "                if class_num == 1:\n",
    "                    res = minimize(compute_train_loss_class_1, x0=start_w, method='Nelder-Mead', \\\n",
    "                                   options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "                elif class_num == 0:\n",
    "                    res = minimize(compute_train_loss_class_0, x0=start_w, method='Nelder-Mead', \\\n",
    "                                   options={'disp': disp,'adaptive': adaptive, 'maxiter': maxiter, 'xatol': xatol})\n",
    "                if res.fun < 0: # ??? - вообще не универсально      \n",
    "                    optim_result.append(res.x)\n",
    "\n",
    "            # Имеет ли большой смысл следующее???\n",
    "            for start_w_new in optim_result:\n",
    "                if class_num == 1:\n",
    "                    res = minimize(compute_train_loss_class_1, x0=start_w_new, method='Nelder-Mead', \\\n",
    "                             options={'disp': False, 'adaptive':True, 'xatol':1})\n",
    "                elif class_num == 0:\n",
    "                    res = minimize(compute_train_loss_class_0, x0=start_w_new, method='Nelder-Mead', \\\n",
    "                             options={'disp': False, 'adaptive':True, 'xatol':1})\n",
    "\n",
    "                for k in range(2):\n",
    "                    if class_num == 1:\n",
    "                        res = minimize(compute_train_loss_class_1, x0=res.x, method='Nelder-Mead', \\\n",
    "                                 options={'disp': False, 'adaptive':True})\n",
    "                    elif class_num == 0:\n",
    "                        res = minimize(compute_train_loss_class_0, x0=res.x, method='Nelder-Mead', \\\n",
    "                                 options={'disp': False, 'adaptive':True})\n",
    "\n",
    "                optim_result_new += [[res.fun, res.x]] # , start_w\n",
    "\n",
    "            optim_result_new = pd.DataFrame(optim_result_new)\n",
    "            optim_result = optim_result.sort_values(0).head(1)\n",
    "            hyperplane_coefficients = optim_result[1].values[0]\n",
    "            print('Time taken for optimization: {0}'.format(time.time() - start_time))\n",
    "#                 print('The best result was on the step {0}'.format(optim_result[0].values[0]))\n",
    "            print('The minimum of the loss function: {0}'.format(optim_result[0].values[0]))\n",
    "\n",
    "#             self.weights_hp_3 = hyperplane_coefficients\n",
    "            return hyperplane_coefficients\n",
    "        \n",
    "    def cutter(X, w):\n",
    "        \"\"\"\n",
    "            Function that makes binary targets for rational numbers\n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :param w: вектор оптимальных весов\n",
    "            :returns: бинаризованные предсказания целевой переменной\n",
    "        \"\"\"\n",
    "        linear = np.dot(X, w)\n",
    "        linear[linear < 0] = 0\n",
    "        return np.sign(linear)\n",
    "    \n",
    "    # TODO:\n",
    "    def fit_predict(X, y, optim_params):\n",
    "        \"\"\"\n",
    "            Fit the algorithm and predict the target on the train sample \n",
    "            \n",
    "            :param X: матрица признаков\n",
    "            :param y: вектор истинных значений целевой переменной\n",
    "            :param optim_params: dict: словарь параметров оптимизатора \n",
    "            :returns: предсказания таргетов на оучающей выборке\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "#         preds = np.zeros(len(y))\n",
    "#         train_preds = pd.DataFrame(y, columns=['TARGET'])\n",
    "#         train_preds['PEDICTIONS'] = 0\n",
    "        \n",
    "        for hp_num in range(1, 4):\n",
    "            k = 10\n",
    "#             X_1 = np.array([[]])\n",
    "            while True:\n",
    "                self.L = 2 ** k\n",
    "                hp_weights_class_1 = make_hyperplane(class_num=1, self.X_train, number_of_hyperplane=hp_num, \\\n",
    "                                             c=0.1, cycle_range=100, disp=False, \\\n",
    "                                            adaptive=True, maxiter=None, xatol=None)\n",
    "                hp_weights_class_0 = make_hyperplane(class_num=0, self.X_train, number_of_hyperplane=hp_num, \\\n",
    "                                             c=0.1, cycle_range=100, disp=False, \\\n",
    "                                            adaptive=True, maxiter=None, xatol=None)\n",
    "                cut_1 = cutter(self.X_train, hp_weights_class_1)\n",
    "                cut_0 = cutter(self.X_train, hp_weights_class_0)\n",
    "                X_1 = self.X_train[cut_1 == 1]\n",
    "                X_0 = self.X_train[cut_0 == 1]\n",
    "                if X_1.shape[0] < self.N and X_0.shape[0] < self.N:\n",
    "                    k -= 1\n",
    "                    continue\n",
    "                else:\n",
    "                    if X_1.shape[0] > X_0.shape[0]:\n",
    "                        self.weights_hp.append(hp_weights_class_1)\n",
    "#                         X_class_1 = self.X_train[cut_1 == 1]\n",
    "#                         preds[cut_1 == 1] = probability(X_class_1, hp_weights_class_1)\n",
    "                        \n",
    "                        self.X_train = self.X_train[cut_1 == 0]\n",
    "                        self.y_train = self.y_train[cut_1 == 0]\n",
    "                        \n",
    "                    else X_1.shape[0] > X_0.shape[0]:\n",
    "                        self.weights_hp.append(hp_weights_class_0)\n",
    "#                         X_class_0 = self.X_train[cut_0 == 0]\n",
    "#                         preds[cut_0 == 0] = probability(X_class_0, hp_weights_class_0)\n",
    "                        \n",
    "                        self.X_train = self.X_train[cut_0 == 1]\n",
    "                        self.y_train = self.y_train[cut_0 == 1]\n",
    "                    break\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_hp = dict()\n",
    "weights_hp == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
